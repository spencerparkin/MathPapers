\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% Can we make this better?
\addtolength{\oddsidemargin}{-.575in}
\addtolength{\evensidemargin}{-.575in}
\addtolength{\textwidth}{1.0in}
\addtolength{\topmargin}{-.575in}
\addtolength{\textheight}{1.25in}

\newcommand{\R}{\mathbb{R}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\prl}{\parallel}
\newcommand{\prp}{\perp}

\swapnumbers
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[section]

\title{Documentation on Octane's\\Geometric Algebra}
\author{Spencer T. Parkin}

\begin{document}
\maketitle

\section{Motivation and Introduction}

Many people have come to me with questions about
the geometric algebra types supported by the Octane Engine.
The purpose of this document is to educate people on
some basic geometric algebra so that they can make better use
of these
data types in their programming work.  Perhaps the most important data type is
the rotor.  A lot of background is covered before a
treatment of rotors is given, but it is worth the effort.
Some problems you face might be more approachable with
geometric algebra than traditional methods.
We do not discuss any homogeneous models invented for
geometric algebra, such as the conformal model.
Though Octane may one day make use
of such a model, it is beyond the scope of this document.
At the time of this writing, Octane implements a geometric
algebra generated by a 3-dimensional vector space, and this
will be our focus.  Anything learned here will still apply to
future expansions of Octane's geometric algebra support.

Lastly, let me say here that the author has gone to great lengths to
insure the accuracy of this document.  Even still, if you find
what you believe to be an error, please inform the author so that
we can get it fixed.

\section{Blades and the Wedge Product}

We will let $\V^3$ denote our 3-dimensional vector space.
This is the space of vectors you are familiar with in your programming work.
You know how to add them, you know how to scale them, and you've
done lots of other algebra with them.  You're familiar with the dot product
and the cross product.  Maybe you've even done some vector calculus.
In any case, we're going to keep all of these
things as tools we can use in geometric algebra.  Surprise!  You already know
some geometric algebra!  We won't really need the
cross product, however, because what we'll
find is that it is a special case of what we can already do in geometric algebra.
Of course, the cross product is still supported in code, but after coming
to know the wedge product, it is possible that you may find cases where
you're using the wedge product when otherwise you might have used
the cross product.

\subsection{What is the wedge product?}

The wedge product is used to wedge vectors together to form what
we call blades.  Formally, if $\{v_1,v_2,\dots,v_k\}$ is a set
of $k$ vectors taken from $\V^3$, then we define the wedge product
\begin{equation*}
v_1\wedge v_2\wedge\dots\wedge v_k
\end{equation*}
to be a non-zero $k$-blade if and only if $\{v_1,v_2,\dots,v_k\}$ is
a linearly independent set of vectors.  Recall from your linear algebra
class that in our case this implies that $k\leq 3$.  Any set of four or more vectors
taken from $\V^3$ must be linearly dependent.  We define the wedge product
of any set of linearly dependent vectors to be zero.

\subsection{What is a $k$-blade?}

A $k$-blade has a geometric interpretation just like vectors do.
In fact, we call non-zero vectors $1$-blades, non-zero scalars $0$-blades,
and we let zero just be zero.  You might think of zero as the absence
of any geometry whatsoever.  The interpretation we choose to give
$k$-blades will explain what they are for our purposes.  Let's start with a pair of
non-parallel vectors $a,b\in\V^3$.  It follows by definition that
their wedge product, $a\wedge b$, is non-zero.  Just as the name blade
implies, we think of $a\wedge b$ as something flat.  Being
non-parllel, the vectors $a$ and $b$ determine the plane containing
$a$ and $b$, and we think of
$a\wedge b$ as a flat area in that plane.  The amount of area,
denoted $|a\wedge b|$, is given by $|a||b|\sin\theta$, where
$\theta$ comes from the familiar equation $a\cdot b=|a||b|\cos\theta$.
So while 1-blades (vectors) have length and direction, 2-blades have
area and orientation, the latter refering to the orientation of a plane,
and the former to the amount of area in that plane.

The keen observer at this point may realize that there are many pairs
of vectors $a,b\in\V^3$ whose wedge product meet this description for
a particular instance of a 2-blade.
Indeed, this is not an accident, and turns out to be one of the strengths
of geometric algebra.  Geometrically, this means that we do not put a
constraint on the shape of the area of $a\wedge b$, so we can think of it
as any shape we want.  Algebraically, this means that 2-blades do not have
a unique factorization in terms of the wedge product.  Often we will choose
a factorization that is most convenient for our purposes.  You'll see many examples
of this in the sections to come.

Lastly, there is another characteristic of the blade $a\wedge b$ taken on to
differentiate it from the blade $b\wedge a$.  This isn't so much a characteristic
of a single blade as it is something that is manifested in the comparison of two such blades
with the same area and in the same plane.  Think of $a\wedge b$ as oriented
the opposite way of $b\wedge a$.  What we might call the front and back of $a\wedge b$
is reversed for $b\wedge a$.  We also say that $a\wedge b$ and $b\wedge a$ have opposite handedness.

Let's now consider a linearly independent subset $\{a,b,c\}$ of $\V^3$.
This non-zero 3-blade $a\wedge b\wedge c$ has volume and orientation.
Notice, however, that the hyper-plane containing $a\wedge b\wedge c$
isn't very interesting, because all 3-blades generated from $\V^3$ will have the
same orientation.  (They all determine the same hyper-plane.)  If we let
$\{x,y,z\}$ be a set of vectors forming an orthonormal
basis for $\V^3$, then it is instructive to express $a\wedge b\wedge c$ as a
scalar multiple of $x\wedge y\wedge z$ as follows.
\begin{equation}
a\wedge b\wedge c =
\det\left[\begin{array}{ccc}\label{psuedo_scalars}
a\cdot x & a\cdot y & a\cdot z \\
b\cdot x & b\cdot y & b\cdot z \\
c\cdot x & c\cdot y & c\cdot z
\end{array}\right]x\wedge y\wedge z
\end{equation}
Here, the absolute value of the determinant gives us the volume $|a\wedge b\wedge c|$,
while the sign of the the determinant would indicate the handedness of $a\wedge b\wedge c$
relative to $x\wedge y\wedge z$.  From this point on we will think of $x\wedge y\wedge z$
as being right-handed.  This is an arbitrary decision, but important so that we're all
thinking about it in the same way.  Being right-handed, $x$ is the index finger of
your right hand, $y$ is the middle finger, and $z$ is the thumb.

In closing, we'll note here that just as vectors are not thought of as residing at any
particular location in space, the same is said for blades in general.  This is yet
another strength of the algebra, and of which you are already familiar as no doubt you
have often experienced the convenience of visualizing vectors in various locations
for various reasons.

\subsection{How do $k$-blades add?}\label{add_blades_section}

You already know how to add vectors geometrically.  2-blade addition
can be defined in terms of vector addition.  Given a 2-blade $c\wedge a$
and a 2-blade $c\wedge b$, we define their sum to be $c\wedge (a+b)$.
(Try to visualize this.  Draw a picture if necessary.)
Similarly, we define $a\wedge c+b\wedge c$ as $(a+b)\wedge c$.  (Notice
that this implies the distributivity of the wedge product over addition.)
At this point you might be asking: how do we add the blades
$a\wedge b$ and $c\wedge d$ in general?  It might seem that our definition
of 2-blade addition is inadiquite to the task, but it isn't!
We need only make three observations.  First, realize that $\{a,b,c,d\}$
is a subset of $\V^3$ and therefore linearly dependent.
Secondly, notice that we can rotate $a\wedge b$
and $c\wedge d$ in their respective planes without altering the
blades in question.  Lastly, realize that
we can lengthen $a$ while shortening $b$ without altering $|a\wedge b|$.
These last two observations take advantage of the non-unique factorizations
of blades.  The first observation assures us that if we rotate
$a\wedge b$ and $c\wedge d$ appropriately, we can get the vectors
$a$ and $c$ into alignment.  We then adjust the length of $a$ to be
that of $c$ while adjusting the length of $b$ to maintain the
area of $a\wedge b$.  Then once $a=c$, we have $a\wedge b+c\wedge d=a\wedge(b+d)$.
Realize that the vectors $a$, $b$, $c$, and $d$ in this equation are not
necessarily the ones we started with!

Our discussion of 2-blade addition brings up an important point.
That is, if $\{a,b,c,d\}$ is a set of 4 linearly independent vectors,
then the 2-blades $a\wedge b$ and $c\wedge d$ do not add together!
This is because no refactorizations of the blades can be found that
allow us to find a common vector factor.  If we were to imagine
each blade as a circle of area at the origin, notice that these circles do not
intersect, because they exist in disjoint vector sub-spaces.
(Strictly speaking, no two vector sub-spaces are disjoint, because
they both contain zero.  But for our purposes, we will say that two such spaces are disjoint
if there does not exist a non-zero vector in both spaces.)
In such a case, the sum of these blades is just what it is, and
we tote them about as a pair throughout our calculations.
This is not a new idea.  Recall your study of complex numbers.

Now notice that no set of 4 linearly independent vectors can
be found in $\V^3$.  It follows that all 2-blades generated from
$\V^3$ add together as 2-blades.  This is an important result that we will
refer to again in subsection $\eqref{all_together_section}$.

In the previous section we saw that all 3-blades are scalar
multiples of one another, because they're all scalar multiples
of $x\wedge y\wedge z$.  We will give $x\wedge y\wedge z$ a
special symbol $I$, and call it the unit-psuedo scalar.
We'll find this useful as you'll see in sections to come.  Start likening
it to the imaginary unit $i$ from complex analysis.

So what about adding an $i$-blade with a $j$-blade when
$i\neq j$?  These don't add to a single blade.  Again,
we simply tote these about as a pair.  Sums of blades
of various grade, ($k$ being what we refer to as the grade of
a $k$-blade), are the form of the general element in our
geometric algebra, as we'll see in subsection $\eqref{all_together_section}$.

\subsection{What of the commutativity of the wedge product?}

We've seen that the wedge product is left and right distributive
over addition, and we have implied its associativity in our discussion
of it, which really follows directly from our definition of the product.
But what can we say about its commutativity?  At this point, we now have
enough to prove something about the commutativity of the wedge product.
Let $a\wedge b$ be a non-zero 2-blade.  Now convince yourself
that $a\wedge b=b\wedge(-a)$.  (Don't hesitate to draw a picture of this.)
These have the same area, orientation,
and handedness.  It now follows that
$a\wedge b+b\wedge a=b\wedge(-a)+b\wedge a=b\wedge(a-a)=0$.
So we see that $a\wedge b$ and $b\wedge a$ are additive inverses
of one another.  We can express this as
\begin{equation*}
a\wedge b = -(b\wedge a),
\end{equation*}
showing that the wedge product is anti-commutative.  Furthermore,
we've shown that $-(b\wedge a)=b\wedge(-a)$, and it is easy to
see that $b\wedge(-a)=(-b)\wedge a$.  Together, these show that
the sign commutes across the wedge product so that there is no ambiguity
in the statement $a\wedge b=-b\wedge a$, which is what we'll prefer
to write when making use of the anti-commutative property of the wedge product.
In general, we will take for granted the
fact that scalars commute and distribute with all other elements
and operations of our algebra.

Notice that the anti-commutativity of the wedge product in the
context of equation $\eqref{psuedo_scalars}$ is consistent with what
we know in linear algebra about what happens to the sign of
determinents when we interchange rows and columns of a matrix.
This is no accident!

\subsection{Putting it all Together}\label{all_together_section}

We now have enough geometric algebra under our belts to make a complete
picture of every element in the algebra currently supported by the Octane Engine.
We'll do this by comming up
with a basis for the algebra.  While such a basis is needed to do geometric
algebra on the computer, it's important to realize that in practice, when
we're doing geometric algebra on paper, we do not need to refer to a basis
as we do in linear algebra.  This is another one of the strengths of geometric
algebra, and interestingly, what this often means is that formulas and results we
find using geometric algebra are independent of dimension.  That is, if we
derive a formula that holds in 3 dimenions, it will likely generalize to holding
in all dimensions without any additional work!  This happens if we don't make any
assumptions along the way that depend on the dimensionality of the generating vector space.

To generate a basis, we start with the orthonormal basis $\{x,y,z\}$ of
$\V^3$ used earlier, and then consider what terms show up in the expansion
of the product
\begin{equation}\label{expand_me}
\bigwedge_{i=1}^k (\alpha_i x+\beta_i y+\gamma_i z),
\end{equation}
for $k=1,2,3$.  (The scalars $\alpha_i$, $\beta_i$,
and $\gamma_i$ are not important here.)  When $k=1$, we get $x$, $y$, and $z$, which are simply
the basis elements for $\V^3$.  When $k=2$, we get $x\wedge y$, $y\wedge z$,
and $x\wedge z$, after collecting terms.
When $k=3$, we get $x\wedge y\wedge z$, after collecting terms.  (Try using $\eqref{expand_me}$
to prove $\eqref{psuedo_scalars}$.  Let $\alpha_1=a\cdot x$, $\beta_1=a\cdot y$, $\gamma_1=a\cdot z$,
let $\alpha_2=b\cdot x$, $\beta_2=b\cdot y$, $\gamma_2=b\cdot z$, and let $\alpha_3=c\cdot x$,
$\beta_3=c\cdot y$, and $\gamma_3=c\cdot z$.)
Throwing in 1 as the basis element for the non-zero scalars, this suggests
the following set of basis elements.
\begin{equation*}
\{1,x,y,z,y\wedge z,z\wedge x,x\wedge y,x\wedge y\wedge z\}.
\end{equation*}
Here we have used a variation of the 2-blade basis elements that we'll
find convenient.  Notice that the geometric algebra is $2^3=8$ dimensional.

We now see that the general element of our algebra is some linear combination
of these basis elements.  These are the multivectors in the Octane Engine.
The other vector types are special cases of this.
Outside of the computer we could simply describe the general element as
a sum of blades of grades zero, one, two, and three, realizing that zero takes
on any grade we want, and that we can absorb scalars into the lengths, areas,
and volumes of blades.  This brings us to an important discussion about the
geometric types supported by the Octane Engine.  To understand why they're named
the way they are, we need to introduce a bit of notation and terminology.

Letting $\G^3$ denote Octane's 8-dimensional geometric algebra, we can say
that for all $g\in\G^3$, that
\begin{equation*}
g = \sum_{k=0}^3\langle g\rangle_k,
\end{equation*}
where $\langle g\rangle_k$ denotes the grade $k$ part of $g$.
The grade $k$ part of $g$ is the sum of all $k$-blades in $g$.
If there were no other blades of a different grade in $g$ other than $k$,
then we could express this as $g=\langle g\rangle_k$, and we would say that
$g$ is homogeneous of grade $k$.  An element $g\in\G^3$ homogeneous of
grade 1 is called a vector.  An element homogeneous of grade 2 is called
a bivector, and an element homogeneous of grade 3 is called a trivector.

We now come to an important point about our algebra $\G^3$.  In our algebra,
all bivectors are 2-blades and all tivectors are 3-blades.  This is because
all 2-blades add together as 2-blades and all 3-blades add together as 3-blades.
Do not make the mistake of believing that in general, all $k$-blades add
together as $k$-blades.  This is not true!  In general, all $k$-blades are
$k$-vectors, but not all $k$-vectors are $k$-blades.  We saw an example of
this in subsection $\eqref{add_blades_section}$ when we considered the sum $a\wedge b+c\wedge d$.  This is
a 2-vector, but it is not a 2-blade.  These distinctions come up in geometric
algebras generated by vector spaces of dimensions greater than 3.  So when using
bivectors and trivectors in Octane, realize that these are blades, but only because
Octane currently implements $\G^3$ and not $\G^n$ for some $n>3$.  A reminder of
this fact is also embedded in the naming scheme Bryant Collard (the software architect
of Octane's geometric algebra system) has given to these types.
The "3d" appended to the name "bivector" reminds you that these are bivectors
taken from $\G^3$, which again, are 2-blades.

In closing, everything that we have described up to this point in the document is a Grassman
algebra, sometimes called an algebra of an outter product.  Our task now
is to take it to a Clifford algebra by definning a dot product on it,
sometimes called an inner product.  This is the goal of the following sections.

\section{The Geometric Product}

Here we will introduce the geometric product initially as a tool for studying
a generalization of the dot product, and then go on to see that it is a fundamental
product in its own right.  The geometric product will become our main tool in formulas
for common geometric operations such as reflections, projections, rejections,
and rotations.  That's right, I said rejections, but thankfully it doesn't have anything
to do with getting rejected by women.

\subsection{What is the Geometric Product?}

Given any two vectors $a,b\in\V^3$, we define
\begin{equation}\label{gp_def}
ab = a\cdot b+a\wedge b
\end{equation}
to be the geometric product of $a$ and $b$, where $(\cdot)$ is
the familiar dot product, and $(\wedge)$ is the now familiar wedge
product.  The reader can
easily check that this product commutes whenever $a$ and $b$
are parallel vectors, and anti-commutes whenever $a$ and $b$
are perpendicular vectors.  The distributivity of this product
follows from the distributivity of the dot and wedge
products.  (We will find that the product is distributive
over addition with respect to any pair of elements in $\G^3$.)
As it stands now, there is nothing we can say about
the associativity of this product.  To see why, consider
the product $aab$.  If we were to disambiguate this as
$a(ab)$, then we get $(a\cdot b)a+a(a\wedge b)$.
The term $(a\cdot b)a$ is defined, but $a(a\wedge b)$ is not.
Seeing that our definition of the geometric product does not
predetermine its associativity, we are free to simply define it as
associative.  It then follows that $a(ab)=(aa)b=|a|^2 b$,
and we see that $a(a\wedge b)=|a|^2 b - (a\cdot b)a$.
We now have a formulation for the geometric product of $a$
and $a\wedge b$.  As one of the main results of this section,
we will find a formula for the geometric product between a
vector and a $k$-blade.

Later on we'll see that the geometric product of two
vectors is what we'll call a rotor.  Rotors can be used
to represent transformations that scale and rotate any
element of the algebra, even rotors themselves.
A treatment of rotors will be given in subsection $\eqref{section_rotations}$.

\subsection{How can we Extend the Dot Product?}\label{dot_extend_section}

We do this by defining it in terms of the geometric product.
Possible motivations for our definition are found in the results
we get out of it, most notably those results that are consistent
with other ways in which people have defined the dot product between
blades.  These nice results are a credit to
Clifford who invented the geometric product.

Letting $A_i=a_1\wedge a_2\wedge\dots\wedge a_i$ be an
$i$-blade and $B_j=b_1\wedge b_2\wedge\dots\wedge b_j$
be a $j$-blade, we will define their dot product as
\begin{equation*}
A_i\cdot B_j = \langle A_iB_j\rangle_{|i-j|}.
\end{equation*}
In other words, $A_i\cdot B_j$ is the grade $|i-j|$ part
of the geometric product between $A_i$ and $B_j$.  Now, this
may seem silly, because at first glance, such a geometric
product appears to be undefined, but it isn't!  The reason comes
from two observations.  The first is that we have defined
the geomtric product to be associative, and the second is
that we can find refactorizations of $A_i$ and $B_j$
such that they may be expressed in terms of the geometric product.
That is, without loss of generality, we can assume
that the sets $\{a_k\}_{k=1}^i$ and $\{b_k\}_{k=1}^j$ each
form an orthogonal basis.  It follows that
\begin{equation*}
A_i\cdot B_j = \langle a_1a_2\dots a_ib_1b_2\dots b_j\rangle_{|i-j|}.
\end{equation*}
The key to seeing this is realizing that the geometric product \emph{is}
the wedge product among a set of pair-wise orthogonal vectors.
Admittedly, in this case, using $\eqref{gp_def}$ to rewrite $a_1\wedge a_2\wedge\dots\wedge a_i$
as $a_1a_2\dots a_i$ is still a bit of a stretch for us at this point if we were to try
to prove it formally, but in order to build our algebra from the ground up, it is something
we'll have to take for granted.  Consider an inductive proof later on in your study.

Let's do an example.  Suppose we want to find the dot product
between a vector $a\in\G^3$ and a 2-blade $B\in\G^3$.  Now, since
there exist vectors $b,c\in\G^3$ such that $B=b\wedge c$ and
$b\cdot c=0$, we can write $B=bc$.  It follows that
\begin{equation*}
a\cdot B = \langle abc\rangle_1.
\end{equation*}
Reducing the problem of finding their dot product to that of finding
the grade 1 part of a geometric product is nice, because, as we'll
see now and continue to see, the geometric product has a lot of nice
algebraic properties.  Consider now writing $a$ in terms of the
parts $a_{\prl}$ and $a_{\prp}$ of $a$ parallel and perpendicular to $B$, respectively.
Being in the plane of $B$, it is clear that $a_{\prl}$ is a linear combination of $b$ and $c$.
We can express this as
\begin{equation}\label{working_abc}
\langle abc\rangle_1 = \langle (a_{\prp}+a_{\prl})bc\rangle_1 =
\left\langle\left[a_\prp+\left(\frac{a_{\prl}\cdot b}{|b|}\right)\frac{b}{|b|}+
\left(\frac{a_{\prl}\cdot c}{|c|}\right)\frac{c}{|c|}\right]bc\right\rangle_1.
\end{equation}
(Recall your study of vector projections.)
Simplifying this, we get
$\langle abc\rangle_1 = \langle a_{\prp}bc\rangle_1 + (a_{\prl}\cdot b)c - (a_{\prl}\cdot c)b$.
Now notice that $a_{\prp}bc=a_{\prp}\wedge b\wedge c$, which is a 3-blade if $a_{\prp}\neq 0$.
In any case, $\langle a_{\prp}bc\rangle_1=0$.
It now follows that
\begin{equation}\label{vec_dot_blade}
a\cdot B = (a_{\prl}\cdot b)c - (a_{\prl}\cdot c)b,
\end{equation}
and we have our first result about the dot product between a vector and a blade!
What this equation is telling us is that the operation $a\cdot B$ produces a
vector that is a scaled rotation of the orthogonal projection of $a$ down onto the plane of $B$.
The rotation is $\pi/2$ radians with respect to the handedness of $B$, and
the scale is the magnitude of $B$.  To see this, multiply and divide the right
hand side of $\eqref{vec_dot_blade}$ by $|B|=|b||c|$.
\begin{equation*}
a\cdot B = |B|\left[\left(\frac{a_{\prl}\cdot b}{|b|}\right)\frac{c}{|c|} -
\left(\frac{a_{\prl}\cdot c}{|c|}\right)\frac{b}{|b|}\right]
\end{equation*}
Comparing the change of basis between this and that shown in $\eqref{working_abc}$,
we can recognize the $\pi/2$ rotation.  If this rotation is hard to see, realize
that without loss of generality, we could have also chosen $b$ and $c$ such that
the projection of $a$ down onto the plane of $B$ is parallel to $b$ with $a_{\prl}\cdot b\geq 0$.  Furthermore,
we could have required that $|b|=1$ and $|c|=|B|$.  We now see that
\begin{equation}\label{easier_way}
a\cdot B = \langle abc\rangle_1 = \langle a_{\prl}bc\rangle_1 =
\langle |a_{\prl}|bbc\rangle_1 = |a_{\prl}|c = |a_{\prl}||B|\frac{c}{|c|}.
\end{equation}
This makes it even easier to see how the direction of the $\pi/2$ rotation is determined
by the handedness of $B$.  The reader would not be wrong at this point to complain that
we should have done this in the first place, but going through the more extensive steps
to begin with has only strengthened our geometric algebra skills!

Returning to $\eqref{vec_dot_blade}$, notice that replacing $a_{\prl}$ with
$a-a_{\prp}$, this equation simplifies to $a\cdot B=(a\cdot b)c-(a\cdot c)b$.
We know that this holds if the 2-blade $B=bc$, which implies that $b\cdot c=0$.
But does it hold when $B=b\wedge c$ and $b\cdot c\neq 0$?  To investigate this, lets find a refactorization
of $B$ that lets us apply our current result aboug $a\cdot B$.
Assuming $b\cdot c\neq 0$, but $B=b\wedge c\neq 0$, notice that there
exists a scalar $\lambda$ such that $(b+\lambda c)\cdot c=0$.
(We could use $\lambda=-(b\cdot c)/|c|^2$, but there is no need to complicate
our calculations with the extra symbols.)  Now notice that $B=(b+\lambda c)\wedge c = (b+\lambda c)c$.
It then follows by our earlier result that
\begin{align}
a\cdot(b\wedge c) &= a\cdot((b+\lambda c)c)\nonumber \\
 &= (a\cdot(b+\lambda c))c - (a\cdot c)(b+\lambda c)\nonumber \\
 &= (a\cdot b)c + \lambda(a\cdot c)c - (a\cdot c)b - \lambda(a\cdot c)c\nonumber \\
 &= (a\cdot b)c - (a\cdot c)b\label{a_dot_b_wedge_c}.
\end{align}
So the answer is yes, and we have a nice formula for $a\cdot(b\wedge c)$
as a linear combination of $b$ and $c$!

\subsection{Formulas for the Dot and Wedge Products}\label{dot_wedge_gp_formulas}

In this section we will derive useful formulas for the dot and
wedge products between vectors and blades in terms of the geometric
product.  After reading this section, the reader is encouraged to prove that, given the blades
$A_i$ and $B_j$ of the previous section, $A_i\wedge B_j=\langle A_iB_j\rangle_{i+j}$.

Let $a$ be a vector and $A_k=a_1a_2\dots a_k$ be a non-zero $k$-blade.
(Again, we can satisfy this condition if for all $i\neq j$, we let $a_i\cdot a_j=0$.)
Now consider the geometric product $aA_k$.  If we write $a$ as $a_{\prl}+a_{\prp}$,
where $a_{\prl}$ and $a_{\prp}$ are the parts of $a$ parallel and perpendicular
to the blade $A_k$, respectively, then the calculation of $aA_k$ falls through fairly easily.
Let us begin by writing
\begin{equation}\label{aak_aprlak_aprpak}
aA_k = a_{\prl}A_k + a_{\prp}A_k.
\end{equation}
Seeing that for all $1\leq i\leq k$, we have $a_{\prp}\cdot a_i=0$,
it is clear that $a_{\prp}A_k$ is a $(k+1)$-blade, and therefore
homogeneous of grade $k+1$.
It is not too hard to show that $a_{\prl}A_k$ is homogeneous of
grade $k-1$.  To see this, write
\begin{equation}\label{expand_aprl_ak}
a_{\prl}A_k = ((a_{\prl}\cdot a_1)a_1^{-1}+(a_{\prl}\cdot a_2)a_2^{-1}+\dots+(a_{\prl}\cdot a_k)a_k^{-1})A_k,
\end{equation}
where for all $1\leq i\leq k$, we let $a_i^{-1}$ denote the vector $a_i/a_i^2$.
Notice that $(a_{\prl}\cdot a_i)a_i^{-1}A_k$ is
a $(k-1)$-blade, since $a_i^{-1}A_k=-(-1)^iA_k^i$, where
$A_k^i$ denotes the product $a_1a_2\dots a_{i-1}a_{i+1}\dots a_k$.
Notice that we do not immediately claim here that $a_{\prl}A_k$
is a $(k-1)$-blade, because we do not know if the $(k-1)$-blades
in $\eqref{expand_aprl_ak}$ add as a single blade, but we can
say that $a_{\prl}A_k$ is a $(k-1)$-vector.  The reader is encouraged
to later prove that $a_{\prl}A_k$ is indeed a $(k-1)$-blade.  (The key is
in realizing that $a_{\prl}$ is in the vector space represented by $A_k$.
Now let $a_{\prl}$ form part of the basis for that vector space.)

What we have now shown is that $\eqref{aak_aprlak_aprpak}$ can
be rewritten as
\begin{equation*}
aA_k = \langle aA_k\rangle_{k-1} + \langle aA_k\rangle_{k+1},
\end{equation*}
showing that $aA_k$ expands as a multivector having grade
$k-1$ and $k+1$ parts.  Furthermore, by our definitions of
the dot and wedge products, it is immediately clear that
this becomes
\begin{equation*}
aA_k = a\cdot A_k + a\wedge A_k.
\end{equation*}
Notice how this nicely generalizes our definition of the
geometric product in $\eqref{gp_def}$ to vectors and $k$-blades.

Now convince yourself of the following identities.
\begin{align}
a_{\prp}A_k &= (-1)^k A_ka_{\prp}\label{aprp_through_ak} \\
a_{\prl}A_k &= -(-1)^k A_ka_{\prl}\label{aprl_through_ak}
\end{align}
To see $\eqref{aprp_through_ak}$, imagine $a_{\prp}$ as it
anti-commutes its way to the other side of $A_k$.  Use the
same idea with $\eqref{aprl_through_ak}$ for each $a_i^{-1}$
in $\eqref{expand_aprl_ak}$ and notice that in each case, exactly one of the swaps
is commutative instead of anti-commutative.

Using $\eqref{aprp_through_ak}$, then $\eqref{aprl_through_ak}$, we see that
\begin{equation}\label{a_wedge_ak}
a\wedge A_k = \frac{1}{2}(a_{\prp}A_k+(-1)^kA_ka_{\prp})=\frac{1}{2}(aA_k+(-1)^kA_ka).
\end{equation}
To see the last step, replace $a_{\prp}$ with $a-a_{\prl}$.  Using
$\eqref{aprl_through_ak}$, then $\eqref{aprp_through_ak}$, we see that
\begin{equation}\label{a_dot_ak}
a\cdot A_k = \frac{1}{2}(a_{\prl}A_k-(-1)^kA_ka_{\prl})=\frac{1}{2}(aA_k-(-1)^kA_ka).
\end{equation}
Again, replace $a_{\prl}$ with $a-a_{\prp}$ to see the last step.  Together,
$\eqref{a_wedge_ak}$ and $\eqref{a_dot_ak}$ give us a way to calculate
$a\wedge A_k$ and $a\cdot A_k$ without resorting to the definitions
of these products.  These equations also reveal the commutativity of these products
in terms of the parity of $k$.

Let's now do a fun example that uses $\eqref{a_dot_ak}$ to prove $\eqref{a_dot_b_wedge_c}$.
Replacing $b\wedge c$ with $bc-b\cdot c$, we see that
\begin{equation}\label{pattern}
a\cdot(b\wedge c) = \frac{1}{2}(a(b\wedge c)-(b\wedge c)a) = \frac{1}{2}(abc-bca).
\end{equation}
Expanding $ab$ and $ca$ as geometric products, this becomes
\begin{equation*}
2a\cdot (b\wedge c) = (a\cdot b)c - (a\cdot c)b + (a\wedge b)c - b(c\wedge a).
\end{equation*}
We leave it as an exercise for the reader to prove that
$(a\wedge b)c-b(c\wedge a)=-c\cdot(a\wedge b)-b\cdot(c\wedge a)$.
(Try it!  It's not as hard as you might think.)  All that remains to
be shown now is that
\begin{equation*}
a\cdot(b\wedge c) + b\cdot(c\wedge a) + c\cdot(a\wedge b) = 0.
\end{equation*}
This is easy to prove by simply applying the identity in $\eqref{pattern}$
three times.  Give it a try!

\subsection{The Magnitude of Dot, Wedge and Geometric Products}

In this section we study the magnitudes of $a\cdot A_k$
and $a\wedge A_k$ of the previous section.  In so doing,
we gain insight into what these products are doing geometrically.
For example, we can think of the wedge product as extruding
a blade into a new dimension, creating a higher dimensional
volume.  The wedge product is a grade raising operation.
Being a grade lowering operation, how might we interpet the
geometrical actions of the dot product?  As we already saw
in section $\eqref{dot_extend_section}$, the dot product of a vector and a 2-blade
gives us a vector in the plane of the 2-blade most unlike our original vector.
It's worth trying to understand this idea for $k$-blades in general.

Beginning with $a\wedge A_k$, it is possible to see that
$|a\wedge A_k|=|a_{\prp}||A_k|=|a||A_k|\sin\theta$,
where $\theta$ is the angle between $a$ and $A_k$.
(If this is hard for you to see when $k>2$, you're not alone.
I feel the same way.)  To be clear about $\theta$ and $a_{\prp}$,
these come from the equation $a\cdot a_{\prl}=|a||a_{\prl}|\cos\theta$,
where again, $a_{\prl}$ is the orthogonal projection of $a$
down onto the hyper-plane of $A_k$, and $a=a_{\prl}+a_{\prp}$.

Now consider the magnitude of $a\cdot A_k$ when $k>1$.  To investigate
this, we'll employ the ideas used in $\eqref{easier_way}$.
Choose a factorization $a_1\wedge a_2\wedge\dots\wedge a_k$ of $A_k$
such that $a_{\prl}\wedge a_1=0$, $a_{\prl}\cdot a_1>0$, $|a_k|=|A_k|$, and
for all $i\neq j$, we have $a_i\cdot a_j=0$.  It then follows that
$1=\prod_{i\neq k}|a_i|$.  Notice that without loss of generality, we can
require that $|a_1|=1$.  Calculating $a\cdot A_k$, we then get
\begin{align*}
a\cdot A_k &= \langle aa_1a_2\dots a_k\rangle_{k-1} \\
 &= \langle a_{\prl}a_1a_2\dots a_k\rangle_{k-1} \\
 &= \langle |a_{\prl}|a_1a_1a_2\dots a_k\rangle_{k-1} \\
 &= |a_{\prl}|a_2a_3\dots a_k \\
 &= |a_{\prl}|A_k^1,
\end{align*}
where here we're making use of the notation $A_k^i=a_1a_2\dots a_{i-1}a_{i+1}\dots a_k$.
Notice that $|A_k^1|=|A_k|$.  We see now that
$|a\cdot A_k|=|a_{\prl}||A_k|=|a||A_k|\cos\theta$,
where again, $\theta$ is the angle between $a$
and $A_k$.  What are we to make of $A_k^1$?
Geometrically, and informally, we might think of this as $A_k$
rotated in its own hyper-plane until one of its
vectors comes into alignment with the projection
of $a$ onto it, and then having this aligned
vector removed from it.  In this way, the dot product does the reverse
of what the wedge product does.  Let's try to be a bit more precise
about this.

When we calculate $a\wedge A_k$, the only real contribution $a$ gives to
the result is the part of $a$ perpendicular to $A_k$.  This part of $a$
determines which new dimension we extrude $A_k$ into.  Similarly, when we calculate
$a\cdot A_k$, the only real contribution $a$ gives to the result is the part of $a$
parallel to $A_k$.  (Put another way, this is the part of $a$ in the vector space
represented by $A_k$.)  This part of $a$ determines which dimension $A_k$ already
spans and of which we no longer want it to extrude into.  This may not be the
way that most people think about the dot product, but it's the way I like to think
about it.

We now have enough to prove something about the magnitude of the geometric
product between a vector and a blade, provided we make the following definition.
For all $g\in\G^3$, let
\begin{equation*}
|g|^2 = \sum_{k=0}^3 |\langle g\rangle_k|^2.
\end{equation*}
We now see that
\begin{align*}
|aA_k|^2 &= |a_{\prp}A_k+a_{\prl}A_k|^2 \\
 &= |a_{\prp}A_k|^2 + |a_{\prl}A_k|^2 \\
 &= |a_{\prp}|^2|A_k|^2 + |a_{\prl}|^2|A_k|^2 \\
 &= |a|^2|A_k|^2.
\end{align*}
The first step is trivial, the second invokes our definition, the third follows
from our study of $|a\cdot A_k|$ and $|a\wedge A_k|$, and the last step invokes
the Pythogorean Theorem.  Notice that this implies that
\begin{equation}\label{mag_result}
|aA_k|=|a||A_k|.
\end{equation}
In particular, notice that the magnitude of a geometric product of vectors is
the product of the magnitudes of those vectors.

While on the subject of magnitudes,
the reader is incouraged to prove that $A_k^2=(-1)^{T(k-1)}|A_k|^2$,
where $T(k)=k(k+1)/2$ is the $k^{th}$ triangle number.
This lets us express the magnitude of a blade in terms of the geometric product.
It also lets us use geometric squares of blades as denominators
without there being any confusion about commutativity.

\subsection{The Zero Product Property of the Geometric Product}

We prove here an important
result about the geometric product between a vector $a$
and a $k$-blade $A_k$.  What we want to show is that
if $aA_k=0$, then at least one of $a$ and $A_k$ is zero.
We will refer to this as the zero product property of
the geometric product.
To begin, notice that if $aA_k=0$, then
$a\cdot A_k=0$ and $a\wedge A_k=0$, because
no two non-zero blades of differing grades add to zero.
It then becomes sufficient to show that if both
$a$ and $A_k$ are non-zero, then at least one
of $a\cdot A_k$ and $a\wedge A_k$ is non-zero.
If $a\wedge A_k\neq 0$, then we're done.
If not, then it's easy to see that
$a\cdot A_k=aA_k$ reduces to a non-zero $(k-1)$-blade.

Notice that we could have used $\eqref{mag_result}$
to prove this property.  If $aA_k=0$, then $|aA_k|=0$.
This implies that $|a||A_k|=0$.  Now by the zero-product
property of the scalar product, we see that at least
one of $|a|$ and $|A_k|$ is zero.  If $|a|=0$, then
$a=0$.  If not, then $|A_k|=0$ and therefore $A_k=0$.

Lastly, notice that the converse of our result is even
easier to prove.  If at least one of $a$ and $A_k$ is
zero, then clearly $aA_k=0$.  We can now say that
$aA_k=0$ if and only if at least one of $a$ and $A_k$
is zero.

\subsection{The Invertability of the Geometric Product}

A really great algebraic property of the geometric product
is that it is invertable.  Let's explore this with $k$-blades.

We say that a $k$-blade $A_k$ is invertable if there exists
an element we'll denote by $A_k^{-1}$ such that
$A_kA_k^{-1}=1$, which is the multiplicative identity.
What we'll show now is that given any non-zero $k$-blade $A_k$,
such an element always exists and is unique.  Furthermore,
it will become immediately apparent that
$A_k^{-1}A_k=1$, showing that they commute and come in pairs.
That is, if $A_k^{-1}$ is the multiplicative inverse of $A_k$,
then $A_k$ is the multiplicative inverse of $A_k^{-1}$.

To show existence, we need only come up with one example.
Let $A_k^{-1}=\tilde{A_k}/|A_k|^2$, where $\tilde{A_k}$
denotes what we'll define as the reverse of $A_k$.
Choosing a factorization of $A_k$ such that it can
be written as the geometric product of vectors $a_1a_2\dots a_k$,
we define the reverse of $A_k$, denoted $\tilde{A_k}$, as
the product $a_ka_{k-1}\dots a_1$.  Leaving it to the reader
to prove that $A_k\tilde{A_k}=|A_k|^2$, it is now clear
that $A_kA_k^{-1}=|A_k|^2/|A_k|^2=1$.  (We will
define the reverse of any geometric product of vectors $a_1a_2\dots a_k$
to be $a_ka_{k-1}\dots a_1$, whether or not they form a set of pair-wise
orthogonal vectors.)

To show uniqueness, suppose there exists an element $g\neq A_k^{-1}$
such that $A_kg=1$.  It follows that $A_kg=A_kA_k^{-1}$, which implies
that $0 = A_kg - A_kA_k^{-1} = A_k(g-A_k^{-1})$.  But by the zero
product property of the geometric product, we must have at least
one of $A_k$ and $g-A_k^{-1}$ be zero.  Since $A_k\neq 0$,
we have $g=A_k^{-1}$, which is a contradiction.

Before leaving the subject of blade inverses, the reader
should now prove that $A^{-1}=A_k/A_k^2$.  Hint: First
show that $\tilde{A}_k=(-1)^{T(k-1)}A_k$.

\section{Common Geometric Operations}

Here we talk about a number of geometric operations that you might
run across in your programming work.  The first thing we notice is
that this list suffers from a lack of support for affine transformations,
which motivates us to learn one of the homogeneous models of geometric
algebra, but that is beyond the scope of this document.

\subsection{Projections and Rejections}

Given a vector $a$ and a $k$-blade
$A_k$, we know that $a\cdot A_k=a_{\prl}A_k$ and $a\wedge A_k=a_{\prp}A_k$,
where $a=a_{\prl}+a_{\prp}$.  To make this procise, we need to describe
either $a_{\prl}$ as the orthogonal projection of $a$ down onto the
blade $A_k$, or $a_{\prp}$ as a vector with $a_{\prp}\cdot a\geq 0$ and the property that
for all vectors $v$ such that $v\wedge A_k=0$, we have $v\cdot a_{\prp}=0$.  That
$a_{\prl}$ is a projection is clear.  The term rejection was invented to describe
$a_{\prp}$, and we say that $a_{\prp}$ is the rejection of $a$ from $A_k$.
Using what we know so far we can easily come up with formulas for $a_{\prl}$
and $a_{\prp}$ in terms of $a$ and $A_k$.  We immediately get $a_{\prl}=(a\cdot A_k)A_k^{-1}$
and $a_{\prp}=(a\wedge A_k)A_k^{-1}$, but we can do better than this.
Refering back to equation $\eqref{aprp_through_ak}$, we see that
\begin{equation*}
a_{\prp} = a_{\prp}A_kA_k^{-1} = (-1)^kA_ka_{\prp}A_k^{-1} = \frac{A_ka_{\prp}A_k}{(-1)^kA_k^2}.
\end{equation*}
Now realize that $a_{\prp}A_k=a\wedge A_k$, and $A_k(a\wedge A_k)=A_k\cdot(a\wedge A_k)$.
Similarly, we can claim that $A_ka_{\prp}A_k=(A_k\wedge a)\cdot A_k$.  Our formula
for $a_{\prp}$ now becomes
\begin{equation}\label{vec_rej}
a_{\prp} = \frac{A_k\cdot(a\wedge A_k)}{(-1)^kA_k^2} = \frac{(A_k\wedge a)\cdot A_k}{(-1)^kA_k^2},
\end{equation}
where either form works.  Refering back to equation $\eqref{aprl_through_ak}$, we see
that
\begin{equation*}
a_{\prl} = a_{\prl}A_kA_k^{-1} = -(-1)^kA_ka_{\prl}A_k^{-1} = \frac{A_ka_{\prl}A_k}{-(-1)^kA_k^2}.
\end{equation*}
Now just as before, we can show that the numerator takes on the form of either
$A_k\cdot(a\cdot A_k)$ or $(A_k\cdot a)\cdot A_k$.  Interestingly, this shows
that in this case, the dot product is associative.  (Be careful.  The dot product
is not associative in general.  See if you can find an example.)  Our formula
for $a_{\prl}$ now becomes
\begin{equation}\label{vec_proj}
a_{\prl} = \frac{A_k\cdot a\cdot A_k}{-(-1)^kA_k^2}.
\end{equation}
It is a worth-while exercise for the reader at this point to
verify formulas $\eqref{vec_rej}$ and $\eqref{vec_proj}$ for
$k=1,2,3$.  Geometric arguments based upon what we know about
certain operations are just as good as purely algebraic proofs.
Use a combination of both.

\subsection{The Cross Product}

Remember the unit psuedo-scalar $I$ we defined in subsection $\eqref{add_blades_section}$?
Well, we're going to start putting it to use.
Let's first prove an interesting fact about it in $\G^3$.
Like scalars, $I$ commutes with all other elements in $\G^3$.
That $I$ commutes with other 3-blades is trivial.
That $I$ commutes with scalars is even more trivial.
So let's consider $aI$ for any vector $a\in\G^3$ and
$BI$ for any bivector (2-blade) $B\in\G^3$.  Starting with
$aI$, we have
\begin{align*}
aI &= ((a\cdot x)x+(a\cdot y)y+(a\cdot z)z)xyz \\
 &= (a\cdot x)yz+(a\cdot y)zx+(a\cdot z)xy \\
 &= xyz((a\cdot x)x+(a\cdot y)y+(a\cdot z)z) = Ia.
\end{align*}
The proof of $BI$ is similar, and so I'll leave it to you
to prove that $BI=IB$.  Notice from our calculations
that $aI$ is a 2-blade and $BI$ is a 1-blade!  This begs
the question of what geometrical relationship $aI$ might
have with $a$ and $BI$ with $B$.

Let us first consider $a$ and $aI$.  One way to go about
investigating their relationship is to simply compute
their geometric product.  Seeing that $aaI=|a|^2I$ isn't
particularly enlightening, but if we instead write
$aaI = a\cdot(aI)+a\wedge(aI)$, then our knowledge about
the geometrical interpretations of the dot and wedge products
can help us relate $a$ to $aI$.  Seeing that $aaI$ is
homogeneous of grade 3, it immediately follows that
$a\cdot(aI)=0$, showing that $a$ is orthogonal to the
blade $aI$.  The act of multiplying $a$ by
the unit psuedo-scalar is therefore a way of finding a
2-blade having $a$ as a normal vector.  It then becomes
natural to ask: how will the area and handedness of this
blade relate to the length and direction of the $a$?
Well, using our result in $\eqref{mag_result}$, we
see that $|aI| = |a||I| = |a|$,
showing that this blade's area is the length of $a$.
To investigate the handedness of $aI$, we compare
the handedness of $a\wedge(aI)$ to $I$.  One way
to do this is to see that $a\wedge(aI)/|a|^2=I$.
The reader can check that these are equal.  Being equal, it
is clear that these 3-blades have the same handedness.
What this tells us is that if we image $x$ as pointing
to the front side of $y\wedge z$, then we can think of
$a$ as pointing to the front of $aI$.

An analysis of the relationship between $B$ and $BI$ is left
as an exersize for the reader.  After you've done this, it
becomes clear that we can define the cross product between
vectors $a$ and $b$ as
\begin{equation*}
a\times b = -(a\wedge b)I.
\end{equation*}
We will not find any need to use the cross product in this paper.

When we take any element $g\in\G^3$ and compute $gI$, we call
this taking the dual of $g$.  Since rotors are elements in $\G^3$
having parts of grade zero and two, the duals of rotors are those
elements of $\G^3$ having parts of grade one and three.  These
are refered to as rotor-duals in code.

\subsection{Finding Angles}

Finding the angle between two vectors is something we often do.
What about finding the angle between two 2-blades?  One way we
can come up with this angle is to use what we know about duals.
Convince yourself that if $\theta$ is the angle between
the 2-blades $A$ and $B$, then $(AI)\cdot(BI) = |AI||BI|\cos(\pi-\theta)$.
(Don't hesitate to draw a picture of this.)
The right-hand side of this simplifies as $-|A||B|\cos\theta$.
For the left-hand side, we see that
\begin{equation*}
(AI)\cdot(BI) = \langle AIBI\rangle_0
 = \langle AI^2B\rangle_0
 = -\langle AB\rangle_0
 = -A\cdot B.
\end{equation*}
This gives us a nice result!  The angle $\theta$ between the 2-blades
$A$ and $B$ is therefore given by
\begin{equation*}
A\cdot B = |A||B|\cos\theta.
\end{equation*}

\subsection{Finding Intersections}

Consider the intersection between a line and a plane.
Since any such problem can be translated for convenience, we will
assume here that the plane contains the origin.  Bivectors in $\G^3$,
(2-blades), are natural candidates as representatives of planes.
Let $P$ be a 2-blade representing our plane, and let vectors
$a$ and $b$ represent a point and the direction of our line, respectively.
We can now reason that the point of intersection, if it exists, between our line
and the plane is the point $a+\lambda b$ where
$(a+\lambda b)\wedge P=0$.  In the course of solving for $\lambda$,
we come to $\lambda b\wedge P = -a\wedge P$.  Now since we can
multiply both sides on the right or left by $(b\wedge P)^{-1}$
to isolate $\lambda$, there should be no confusion when we write
\begin{equation*}
\lambda = -\frac{a\wedge P}{b\wedge P}.
\end{equation*}
This is really just the ratio of two volumes, seeing that both
terms are psuedo-scalars.  It's curious to think that the geometry
of our problem is solved by such a ratio.  Clearly there is no
solution when $b\wedge P=0$, and this makes sense since in this
case the direction of our line is parallel to the plane represented
by $P$.

Suppose now that we wanted to find the intersection between two
planes.  We can represent our two planes with the 2-blades $A$ and $B$.
We'll assume that our planes both contain the origin, since the general
problem can be reduced to this case.  In the case that the planes being
represented are not the same plane, a vector at the origin contained in both planes
suffices to represent their intersection.  It is not hard to see
that $((AI)\wedge(BI))I$ is such a vector.  Notice that this goes
to zero in the case that $A$ and $B$ are parallel.  There is a problem
with this solution, however.  The validity of the result depends on
the fact that both $A$ and $B$ are in $\G^3$, and therefore must intersect.
If, however, $A$ and $B$ represented disjoint vector sub-spaces, then
$((AI)\wedge(BI))I$ cannot be their intersection, because they don't intersect.
A better solution would be the expression $(AI)\cdot B$.  This is also zero
in the case that $A$ and $B$ are parallel, and it is zero when $A$ and $B$
are wedged from disjoint vector sub-spaces.  The result is an expression
that works not just in $\G^3$, but any geometric algebra containing $\G^3$,
provided we use the appropriate psuedo-scalar for that algebra.  Remember
that $I=xyz$ for $\G^3$ only.

\subsection{Finding Distances}

Suppose we wished to find the shortest distance from a point to a plane.
Again, without loss of generality, we will assume our plane contains
the origin.  Letting $B$ be a unit 2-blade representing our plane and $p$
being a vector representing our point, what we're looking for is simply
the length of the rejection of $p$ from $B$.  Using $\eqref{vec_rej}$,
this is given by $|B\cdot(p\wedge B)|$.  If the reader can simplify this further, then
that would be great, but as it is now, this appears to be a reasonable
calculation one might perform using Octane's geometric algebra system.  This would not
be as efficient as using the plane equation, but if there can be something said
about writing code quickly, then this method has merit.

\subsection{Reflections}

Given a vector $a$ and a vector $b$, we define the vector reflection
of $b$ about $a$ as the vector $b_{\prl}-b_{\prp}$, where $b_{\prl}$
and $b_{\prp}$ are the vector components of $b$ parallel and
perpendicular to $a$, respectively.  Denoting such a reflection as
$b'$, it is easy to derive a formula for $b'$ in terms
of vector projections.  We simply have $b'=2(b\cdot a)a/a^2-b$.
We can get a nicer result, however, if we use the geometric product.
Notice that $b=ba^2/a^2=(b\cdot a)a/a^2 + (b\wedge a)a/a^2$.
Seeing that $b_{\prl}=(b\cdot a)a/a^2$ and $b_{\prp}=(b\wedge a)a/a^2$,
we write
\begin{equation*}
b' = (b\cdot a)a/a^2 - (b\wedge a)a/a^2 = (a\cdot b+a\wedge b)a/a^2 = aba/a^2,
\end{equation*}
and there we have it.
Notice that it can also be written as $b'=aba^{-1}$.

At this point it is a worth-while exercise for the reader to investigate
the idea of reflecting a vector about a 2-blade.  How could such a reflection
be defined?  How could you go about finding a formula for it?

\subsection{Rotations}\label{section_rotations}

Here we finally give a treatment of rotors in the subject of geometric
algebra.  With the background that we now have, it is almost trivial!
Let us begin with the observation that vectors and 2-blades are both
good candidates for representing rotations.
And not surprisingly, if just one of these clearly
represents a rotation, then naturally, so does the other by virtual of
duality.
What we'll find, however, is that the most convenient way for us to
represent a rotation will be by using neither vectors nor 2-blades, but
elements of $\G^3$ we'll call unit-rotors.  In the next section,
we'll discover a special relationship between unit-rotors and the vectors or 2-blades
representing the same rotation.

Our development of the rotor will be similar to that given in $\cite{geoalgforphy}$.
Considering what we know about reflecting vectors about vectors, it is not hard
to convince yourself that a rotation can be achieved by two vector reflections.
Let $a$ and $b$ be a pair of linearly independent vectors taken from $\G^3$.
Given a vector $v\in\G^3$, let $v'$ denote the vector that is the reflection of
$v$ about $a$, then about $b$.  If $v\wedge a\wedge b=0$, then drawing a quick
picture of this is enough to convince yourself that $v$ was rotated in the plane
of $a\wedge b$ by an angle $2\theta$, where $\theta$ is the angle between
$a$ and $b$.  Now consider the case when $v\wedge a\wedge b\neq 0$.
A bit of trigonometry will convince you that 
\begin{equation}\label{two_vec_reflect}
\frac{b\left(\frac{ava}{|a|^2}\right)b}{|b|^2} = \frac{bavab}{|a|^2|b|^2}
\end{equation}
is also a rotation of $v$ by an angle of $2\theta$ and parallel to the
plane of $a\wedge b$.  We can also easily prove this by writing
\begin{equation*}
\frac{bavab}{|a|^2|b|^2} = \frac{ba(v_{\prl}+v_{\prp})ba}{|a|^2|b|^2} =
\frac{bav_{\prl}ab}{|a|^2|b|^2} + v_{\prp},
\end{equation*}
seeing that the vector component $v_{\prp}$ of $v$ perpendicular to $a\wedge b$
is not rotated, but the vector component $v_{\prl}$ of $v$ parallel to $a\wedge b$
is rotated.  Again, all of this is simply based on our previous study of vector
reflections!

Looking again at equation $\eqref{two_vec_reflect}$, we now notice that
this suggests $ba/|ab|$ as an element encoding a rotation.
(Recall our proof that $|ab|=|a||b|$ in $\eqref{mag_result}$.)
Letting $R=ba/|ab|$, a formula for $v'$ in terms of $v$ and $R$ is
then given by
\begin{equation}\label{rot_formula}
v' = Rv\tilde{R}.
\end{equation}
Elements in $\G^3$ that are the geometric product of any two non-zero vectors
are what we call rotors.  Unit-magnitude rotors, refered to as
unit-rotors in Octane, are the geometric elements we use to represent
rotations instead of the traditional quaternion.
Be aware that $\eqref{rot_formula}$ is a rotation formula for unit-rotors.
For non-unit-rotors, it is easy to see that it performs a scaled rotation.
The reader should identify the scale in terms of the magnitude of the rotor.

At this point it is worth showing that the set of all rotors in
$\G^3$ forms a group under the geometric product, and then show
that the set of unit-rotors is a sub-group.  We'll then review a
number of corollaries to this result.  We refer the reader to $\cite[p. 43]{gallian06}$
for the definition of a group.  (Equivilant definitions can also
be found on the internet.)  Under this definition, to show that
the set of all rotors forms a group, we need to show a number of things.
First, we need to show that our rotor multiplication is associative.
But this is easy since it follows immediately from the associativity of
the geometric product.  Secondly, we must show that there exists an
identity rotor.  Clearly, the scalar 1 is a rotor since it is the
geometric product of many example pairs of vectors, and it has the
property of being a multiplicative identity in our case.
Thirdly, we need to show that every rotor has an inverse.
To that end, let $R$ be a rotor.  It then follows by definition that
there exist non-zero vectors $a$ and $b$ such that $R=ab$.
Noticing that $Rba/|ab|^2=1$, the multiplicative identity, we see that
$R^{-1}=\tilde{R}/|R|^2$, which proves the existance of $R^{-1}$
since $|R|\neq 0$.  Lastly, we must show that the set of all
rotors is closed under the operation of the geometric product.
What this means is that for any pair of
rotors $A$ and $B$, there must exist a pair of vectors $a$ and $b$
such that $ab=AB$.  The key to our proof of this is in the realization
that our rotors are taken from $\G^3$.  It follows from this that
there must exist vectors $x,y,z,w\in\G^3$ such that $A=xy$,
$B=zw$, $y=z$, and $|y|=|z|=1$.  Letting $a=x$ and $b=z$,
we now see that
\begin{equation*}
ab = xz = x(1^2)z = xyzw = AB,
\end{equation*}
which is what we wanted to show.  What remains to be shown
is that the set of unit-rotors in $\G^3$ forms a sub-group.  Being
a sub-set of the set of all rotors in $\G^3$, we need only use
the theorem given in $\cite[p. 61]{gallian06}$ to prove our result.
That said, if $A$ and $B$ are unit-rotors, then there exist
vectors $x,y,z,w\in\G^3$ such that $A=xy$, $B=zw$, $y=w$, and $|y|=|w|=1$.
We then have $AB^{-1}=A\tilde{B}=xywz=xz$, and clearly $xz$
is a unit-rotor, since $|x|=|z|=1$.

Showing that the set of all unit-rotors froms a group teaches us
a number of things.  The first and most useful result is that
of rotor concatination.  Suppose we want to perform the rotation
represented by the unit-rotor $R$ followed by the unit-rotor $S$.
Using $\eqref{rot_formula}$, we have
\begin{equation*}
v' = SRv\tilde{R}\tilde{S} = SRv(SR)^{\tilde{}},
\end{equation*}
but realizing that unit-rotors form a group, this reduces to the application
of just one rotor, namely $SR$.

We've also learned that rotors are invertable, which is a good thing
since rotations are clearly reversable.  It shouldn't be hard to convince
yourself that the unit-rotor $R^{-1}=\tilde{R}$ represents the rotation that undoes
the rotation represented by the unit-rotor $R$, by simply rotating in the opposite direction.

Before continuing to the next subsection, we mention here what you may
have already noticed.  The rotation represented by the unit-rotor $R$
is the same rotation represented by $-R$.  This is easy to see.  Just
plug $-R$ into $\eqref{rot_formula}$.  This is what some authors are
refering to when that talk about unit-rotors as being a double cover
for the set of all rotations.

\subsection{The Polar Decomposition of a Rotor}

Let $R=ab$ be a rotor, not necessarily of unit-magnitude.
By the geometric product, we may write
\begin{equation}\label{expand_rotor}
R = a\cdot b + a\wedge b = |a||b|\cos\theta + \frac{a\wedge b}{|a\wedge b|}|a||b|\sin\theta
 = |R|\left(\cos\theta + \frac{a\wedge b}{|a\wedge b|}\sin\theta\right),
\end{equation}
where $\theta$ is the angle between $a$ and $b$.  It is not too hard to
prove that the geometric square of $a\wedge b/|a\wedge b|$ is -1.  You can do
this by either applying a number of identities or by simply finding a refactorization
of any unit-2-blade in terms of a pair of orthogonal unit-vectors.  In any case,
seeing that this 2-blade has this property is a rationalization for re-writing
$\eqref{expand_rotor}$ as
\begin{equation*}
R = |R|\exp\left(\theta\frac{a\wedge b}{|a\wedge b|}\right).
\end{equation*}
This comes from the Tayler series expansions of $\exp(x)$, $\cos(x)$ and $\sin(x)$, each
extended to geometric algebra and using the geometric product.
If $R$ is a unit-rotor, we can now write $\eqref{rot_formula}$ as
\begin{equation*}
v' = \exp(\theta B/2)v\exp(-\theta B/2),
\end{equation*}
where $B$ is a unit-2-blade representing the plane and direction of rotation,
and $\theta$ is the desired angle of rotation.  (It is a worth-while exercise
to show that this formula reduces to $v'=v\exp(\theta B)$ when $v\wedge B=0$.
We will use this result in the next subsection, but leave it to you to prove it.)

From the polar decomposition of a rotor, we can now see how to pick apart
the axis and angle of a rotation, which is a common operation.  We also
frequently construct rotations from axis/angle pairs.  Given an axis
$a$ and an angle $\theta$, the desired rotor is given by
\begin{equation*}
R = \exp(-\theta aI/2),
\end{equation*}
provided that positive angles of rotation are to represent counter-clock-wise
rotations when viewing the axis as pointing toward us.  So that we don't contradict
the 2-blade form of this equation, namely $R=\exp(\theta B/2)$, we have to be
clear about the dual of vectors and 2-blades.  We define the dual of a vector
$a$ to be $aI$, and the dual of a 2-blade $B$ to be $-BI$.  It should now be
easy to show that the dual operation on vectors or 2-blades is its own inverse.
With this convention, how we think of rotations in terms of 2-blades, vectors,
or rotors, will all be consistent.

\subsection{Spherical Linear Interpolation}

In this subsection we show how geometric algebra can be used
to derive the formula for performing the well-known spherical
linear interpolation.

Given a pair of linearly independent vectors $a$ and $b$, each
of unit length and taken from our 3-dimensional
vector space $\V^3$, we wish to uniformly interpolate between them along
the shortest arc of the unit sphere connecting
the tips of $a$ and $b$ by the normalized index $0\leq t\leq 1$.  Notice that
such an arc exists by our requirement that $a$ and $b$ are not parallel to
one another.  Using what we know about rotors, it is easy to
construct the desired interpolation.  We begin by constructing
the rotor that will rotate $a$ toward $b$ so that the ratio
of the angle made between the interpolated vector and $a$ with
the angle made between $a$ and $b$ is exactly $t$.  The desired
rotor is given by
\begin{equation*}
R(a,b,t) = \exp\left(-\frac{a\wedge b}{|a\wedge b|}(t\theta/2)\right),
\end{equation*}
where $\theta$ is the angle made between $a$ and $b$.
Here we have chosen the proper plane of rotation using the
blade $a\wedge b$, and then rescaled it to be of a magnitude
equal to half the desired angle of rotation.  The sign of
the blade is chosen so that the equation
\begin{equation}\label{slerp_unsimplified}
\mbox{slerp}(a,b,t) = R(a,b,t)a\tilde{R}(a,b,t)
\end{equation}
rotates $a$ in the plane of $a\wedge b$ toward $b$ as required.
This is also a formula for the desired interpolation.
Noticing that $a\wedge a\wedge b=0$, we leave it to the
reader to prove that $\eqref{slerp_unsimplified}$ 
reduces to
\begin{equation*}
\mbox{slerp}(a,b,t) = a\exp\left(\frac{a\wedge b}{|a\wedge b|}t\theta\right)
 = a\cos(t\theta) + a\frac{a\wedge b}{|a\wedge b|}\sin(t\theta).
\end{equation*}
From this we see that
we can express the interpolated vector as
a linear combination of $a$ and $a\cdot(a\wedge b)/|a\wedge b|$,
a unit-vector perpedicular to $a$.  The linear combination of
these vectors consists of $\cos(t\theta)$ and $\sin(t\theta)$,
making our result clear from basic trigonometry.  We, however,
will want to find a formula for the interpolated vector as a
linear combination of $a$ and $b$.
To this end, we come up with the following matrix equation
\begin{equation*}
\left[\begin{array}{cc}\cos(t\theta)&\sin(t\theta)\end{array}\right]
\left[\begin{array}{c}a\\a\frac{a\wedge b}{|a\wedge b|}\end{array}\right]
=\left[\begin{array}{cc}f(t)&g(t)\end{array}\right]
\left[\begin{array}{c}a\\b\end{array}\right],
\end{equation*}
where the elements are members of $\G^3$ and matrix multiplication
is as usual, but using the geometric product instead of scalar multiplication.
Before we proceed, it is helpful to put the row-oriented matrices on a common basis.
It is convenient to use the components of each row-vector
parallel and perpendicular to $a$.  Our matrix equation then becomes
\begin{equation*}
\left[\begin{array}{cc}\cos(t\theta)&\sin(t\theta)\end{array}\right]
\left[\begin{array}{cc}a&0\\0&a\frac{a\wedge b}{|a\wedge b|}\end{array}\right]
=\left[\begin{array}{cc}f(t)&g(t)\end{array}\right]
\left[\begin{array}{cc}a&0\\(a\cdot b)a&-(a\wedge b)a\end{array}\right].
\end{equation*}
To see this, recall how the geometric product can be used to find parallel
and perpendicular vector components.
\begin{equation*}
b = ba^2 = (a\cdot b-a\wedge b)a = (a\cdot b)a - (a\wedge b)a.
\end{equation*}
We now solve for the inverse of the row-oriented matrix on the right-hand side.
\begin{equation*}
\left[\begin{array}{cc}a&0\\(a\cdot b)a&-(a\wedge b)a\end{array}\right]
\left[\begin{array}{cc}w&x\\y&z\end{array}\right] =
\left[\begin{array}{cc}1&0\\0&1\end{array}\right].
\end{equation*}
Clearly, $w=a$ and $x=0$.
Solving for $y$, we get
\begin{align*}
 & (a\cdot b)a^2-(a\wedge b)ay = 0 \\
\implies& (a\wedge b)ay = a\cdot b \\
\implies& (a\wedge b)^2y = a(a\wedge b)(a\cdot b) \\
\implies& y = \frac{a(a\wedge b)(a\cdot b)}{(a\wedge b)^2}.
\end{align*}
Solving for $z$, we get
\begin{align*}
 & -(a\wedge b)az = 1 \\
\implies& -(a\wedge b)^2z = a(a\wedge b) \\
\implies& z = \frac{a(a\wedge b)}{-(a\wedge b)^2}.
\end{align*}
Having the inverse of the matrix, we're now ready to solve our original matrix equation.
\begin{align*}
\left[\begin{array}{cc}f(t)&g(t)\end{array}\right]
 &= \left[\begin{array}{cc}\cos(t\theta)&\sin(t\theta)\end{array}\right]
\left[\begin{array}{cc}a&0\\0&a\frac{a\wedge b}{|a\wedge b|}\end{array}\right]
\left[\begin{array}{cc}a&0\\\frac{a(a\wedge b)(a\cdot b)}{(a\wedge b)^2}&
\frac{a(a\wedge b)}{-(a\wedge b)^2}\end{array}\right] \\
 &= \left[\begin{array}{cc}\cos(t\theta)&\sin(t\theta)\end{array}\right]
\left[\begin{array}{cc}1&0\\-\frac{a\cdot b}{|a\wedge b|}&\frac{1}{|a\wedge b|}\end{array}\right] \\
 &= \left[\begin{array}{cc}\cos(t\theta)-\frac{a\cdot b}{|a\wedge b|}\sin(t\theta)
 & \frac{1}{|a\wedge b|}\sin(t\theta)\end{array}\right].
\end{align*}
We can now write $g(t)=\sin(t\theta)/\sin(\theta)$, and we are not
far from a similar result for $f(t)$.
\begin{equation*}
f(t) = \frac{\sin(\theta)\cos(t\theta)-\cos(\theta)\sin(t\theta)}{\sin(\theta)} =
 \frac{\sin((1-t)\theta)}{\sin(\theta)}.
\end{equation*}
Our formula for the spherical linear interpolation now becomes
\begin{equation*}
\mbox{slerp}(a,b,t) = \frac{a\sin((1-t)\theta)+b\sin(t\theta)}{\sin(\theta)},
\end{equation*}
which is what we wanted to show.
That the interpolated vector is always of unit-length follows directly
from our construction of the interpolation formula, as do the other properties
of the interpolation.

Notice that our derivation did not depend on the dimensionality of
the vectors $a$ and $b$.  This means that our formula works for any
pair of unit-length, linearly independent vectors pointing to the
surface of an $n$-dimensional hyper-sphere.  This generalization
came for free in our derivation using geometric algebra.

\section{The Dot Product of $k$-Blades}

If you've read this far, then let's go ahead and
prove the following result for fun.  If $A_k$ and $B_k$ are $k$-blades, not
necessarily wedged from vectors taken from the same $k$-dimensional
vector sub-space, then their dot product is given by
\begin{equation}\label{k_blade_dot_prod}
A_k\cdot B_k = \left|\begin{array}{ccc}
a_1\cdot b_1 & \dots & a_1\cdot b_k \\
\vdots & \ddots & \vdots \\
a_k\cdot b_1 & \dots & a_k\cdot b_k
\end{array}\right|,
\end{equation}
where $A_k=a_1\wedge\dots\wedge a_k$ and $B_k=b_1\wedge\dots\wedge b_k$.
We first prove $\eqref{k_blade_dot_prod}$ for the case when $\{a_i\}_{i=1}^k$
and $\{b_i\}_{i=1}^k$ each form an orthogonal basis.  (Again, these need
not be basis for the same $k$-dimensional vector sub-space.)
Let us proceed by induction.  Checking $\eqref{k_blade_dot_prod}$ for the case
$k=1$ is trivial.  Now assume that $\eqref{k_blade_dot_prod}$ holds for a
fixed integer $k-1\geq 0$.  It follows by definition that
\begin{align*}
A_k\cdot B_k &= \langle A_kB_k\rangle_0 \\
 &= \langle A_k^k(a_k^{\prl} + a_k^{\prp})B_k\rangle_0 \\
 &= \langle A_k^k((a_k\cdot b_1)b_1^{-1} + \dots + (a_k\cdot b_k)b_k^{-1})B_k\rangle_0+
\langle A_k^ka_k^{\prp}B_k\rangle_0 \\
 &= \langle A_k^k((-1)^0(a_k\cdot b_1)B_k^1 + \dots + (-1)^{k-1}(a_k\cdot b_k)B_k^k)\rangle_0 \\
 &= (-1)^0(a_k\cdot b_1)\langle A_k^k B_k^1\rangle_0 + \dots + (-1)^{k-1}(a_k\cdot b_k)\langle A_k^k B_k^k\rangle_0 \\
 &= (-1)^0(a_k\cdot b_1)A_k^k\cdot B_k^1 + \dots + (-1)^{k-1}(a_k\cdot b_k)A_k^k\cdot B_k^k \\
 &= \left|\begin{array}{ccc}
a_1\cdot b_1 & \dots & a_1\cdot b_k \\
\vdots & \ddots & \vdots \\
a_k\cdot b_1 & \dots & a_k\cdot b_k
\end{array}\right|,
\end{align*}
where here we're again making use of the notation $A_k^i=a_1a_2\dots a_{i-1}a_{i+1}\dots a_{k-1}a_k$.
The vectors $a_k^{\prl}$ and $a_k^{\prp}$ are the vector components of $a_k$ parallel
and perpendicular to $B_k$, respectively.  What we've done here is invoke the inductive
hypothesis $k$ times to perform a cofactor expansion along the last row of the matrix.
To see that $\langle A_k^ka_k^{\prp}B_k\rangle_0=0$ when $a_k^{\prp}\neq 0$, realize
that $A_k^k\cdot(a_k^{\prp}B_k)$ is the lowest grade part of the geometric product
$A_k^ka_k^{\prp}B_k$ that has the potential to be non-zero.  This part has grade $|k-1-(k+1)|=2$.
We can now claim by the principle of mathematical induction that $\eqref{k_blade_dot_prod}$
holds for all positive integers $k$.

To complete our proof, all that remains to be shown is that $\eqref{k_blade_dot_prod}$
holds even when either $\{a_i\}_{i=1}^k$ or $\{b_i\}_{i=1}^k$ or both do not form an
orthogonal basis.  Our argument will be based on the Gram-Schmidt orthogonalization
process.  Write $A_k$ as the geometric product $a_1'\dots a_k'$, where $a_1'=a_1$,
and
\begin{equation*}
a_{i>1}' = a_i - \sum_{j=1}^{i-1}(a_i\cdot a_j')(a_j')^{-1}.
\end{equation*}
We can now apply our earlier result and write
\begin{equation*}
A_k\cdot B_k = \left|\begin{array}{ccc}
a_1'\cdot b_1' & \dots & a_1'\cdot b_k' \\
\vdots & \ddots & \vdots \\
a_k'\cdot b_1' & \dots & a_k'\cdot b_k'
\end{array}\right|.
\end{equation*}
To see that this equation still holds when we remove the prime tick marks,
realize that each step of the Gram-Schmidt orthogonalization process translates
into a row (or column) operation where a scalar multiple of one row (or column) is
added to another.  By Theorem 3 of $\cite[p. 192]{lay03}$, this does not change
the value of the determinant.  What we've done here is similar to what we did
in equation $\eqref{a_dot_b_wedge_c}$.

\section{Concluding Remarks}

More than enough material has been covered to this point that the reader should
be able to understand the geometric algebra support offered by the
Octane Engine.  If nothing else, hopefully our treatment of rotors was
enough to give those readers familiar with quaternions a solid understanding
of how rotations are represented in Octane using unit rotors.  Geometric algebra
is a very difficult subject and we have only scratched the surface here.
I have only attempted to write what I think I know about it, and there still remain
many of my own unanswered questions.  But this is a good thing as it is what
drives a personal pursuit of the field.

Geometric algebra does not appear to me to be the end-all be-all of mathematical
tools for solving computational geometry problems.  Of course, this is coming from someone
who is far from a reasonably complete understanding of its applications to
computer graphics.  Even still, I don't think it's ready to stand on its own.
I'll continue to use linear algebra and explore other mathematical models.
As far as geometric algebra goes, perhaps in the future, even better algebraic
structures will be found for use in solving geometry problems, but until then, geometric
algebra has proven to be a promising tool.

\begin{thebibliography}{9}

\bibitem{gallian06}
	Joseph A. Gallian,
	\emph{Contemporary Abstract Algebra}.
	Houghton Mifflin,
	6th Edition,
	2006.

\bibitem{lay03}
	David C. Lay,
	\emph{Linear Algebra and it's Applications}.
	Addison Wesley,
	3rd Edition,
	2003.

\bibitem{dorstetal07}
	Dorst, Fontijne, Mann,
	\emph{Geometric Algebra for Computer Science}.
	Morgan Kaufmann,
	2007.

\bibitem{geoalgforphy}
	Chris Doran, Anthony Lasenby,
	\emph{Geometric Algebra for Physicists}.
	Cambridge University Press,
	2003.

\bibitem{hestenese}
	David Hestenes,
	\emph{New Foundations for Classical Mechanics}.
	Springer,
	2nd Edition,
	1999.

\bibitem{gaprimer}
	Jaap Suter,
	\emph{Geometric Algebra Primer}.
	2003.

\bibitem{gawikientry}
	Wikipedia, "http://en.wikipedia.org/wiki/Geometric\_algebra".

\bibitem{bcollard}
	Bryant Collard, Personal communication.

\end{thebibliography}

\end{document}
