\documentclass{birkjour}

\usepackage{float}
\usepackage{algpseudocode}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem*{ex}{Example}
\numberwithin{equation}{section}

\newcommand{\R}{\mathbb{R}}
\newcommand{\B}{\mathbb{B}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\gd}{\dot{g}}
\newcommand{\gh}{\hat{g}}
\newcommand{\Gd}{\dot{G}}
\newcommand{\Gh}{\hat{G}}
\newcommand{\nvai}{\infty}
\newcommand{\nvao}{o}
\newcommand{\grade}{\mbox{grade}}

%\received{}\accepted{}

\begin{document}

\title{On The Expansion Of Algebraic Expressions In Geometric Algebra}

\author{Spencer T. Parkin}
%\address{102 W. 500 S., \\
%Salt Lake City, UT  84101}
\email{spencerparkin@outlook.com}

%\subjclass{Primary ; Secondary }

%\dedicatory{To my dear wife Melinda.}

\begin{abstract}
Abstract goes here...
\end{abstract}

\keywords{Key words go here...}

\maketitle

\section{Introduction}

While the expansion of algebraic expressions taken from, say, a polynomial ring, are found as a trivial matter
of applying the associative, commutative and distributive properties, and combining like-terms, it is interesting to note
that this is certainly not true of expressions taken from a geometric algebra.\footnote{Factoring may be thought of as the problem opposite of and more
interesting than that of expansion.  In geometric algebra, however, expansion is not entirely trivial, and therefore a subject of interest.}
In this paper, a general stratagy, or algorithm, if you will, is given for the expansion of such expressions, and it is shown that
it is perhaps just as natural to write an element of a geometric algebra as a sum of ``spades'' as it is to
write such an element as a sum of blades.  The term ``spade'' is introduced in Table~\ref{tbl_terms} below,
along with similar, traditional terms found in geometric algebra.\footnote{The term ``versor'' was avoided in
this paper in favour of ``spade'' as a matter of rigour.  Not knowing a term for the algebraic form in question, and not finding
one in the literature, one was made up.}

\begin{table}[H]\label{tbl_terms}\caption{Terms used in GA}
\begin{tabular}{p{1cm}p{9cm}}
Term & Definition \\
\hline
Blade & An outer product of zero or more linearly-independent vectors. \\
Versor & A geometric product of zero or more invertible vectors, not necessarily forming a linearly-independent set. \\
Spade & A geometric product of zero or more vectors, not necessarily forming a linearly-independent set.
\end{tabular}
\end{table}

From these it is clear that every versor is a spade, but not every spade is a versor.

Similar to the concept of grade, that of rank will be introduced in this paper with respect to spades.  As an $r$-blade
refers to a blade of grade $r$, we will let an $r$-spade refer to a spade of rank $r$.  If an element of a geomtric
algebra can be written as a geometric product of vectors, then it is a spade.  The rank of that spade is then the smallest
possible number of vectors for which it can be written as such a product.\footnote{While the correctness of many identities of this paper
do not require a spade to be written in the most compact form, the concept of rank would be ill-defined without its consideration.}   Note that blades of grade zero
are indistinguishable from spades of the same rank as each denotes the set of all scalars.

Unlike versors, note that spades do not form a group over the geometric product by simple reason that not every
spade is invertible with respect to the geometric product.  They are important to study, however,
because they appear more often in consideration of the typical expression taken from a geometric algebra.
Put a better way, versors are a special case of spade, and we want to keep our discussion as generally applicable as possible.

As this paper moves along, references will be made to Section~\ref{sec_identities_appendix}, which readers less familiar with geometric
algebra may wish to visit before continuing.
No axiomatic development of geometric algebra is given in this paper, but Section~\ref{sec_identities_appendix} does serve to releave the main
body of the paper from finer details that would otherwise complicate or obfuscate the derivisions being made.  For an axiomatic
development of geometric algebra, see \cite{}.

\section{Symmetry Between The Outer And Geometric Products}

As will be shown by the results established in this section, there is perhaps a lot more in
common between the outer and geometric products than one might think.  Certainly the outer and
inner products play a complementary role in the building up or tearing down of blades, respectively, but from a
purely algebraic perspective, consider the following well-known definition of the geometric product
between two vectors $a$ and $b$.
\begin{equation}\label{equ_ab_is_a_dot_b_and_a_wedge_b}
ab = a\cdot b + a\wedge b
\end{equation}
The right-hand side of equation \eqref{equ_ab_is_a_dot_b_and_a_wedge_b} is a sum of blades, while the left-hand side is a sum of spades;
in this case, exactly one; namely, $ab$.  Thus, the element $ab$ appears naturally in a sum-of-blades and
sum-of-spades form, but what of the element $a\wedge b$?  Rearranging \eqref{equ_ab_is_a_dot_b_and_a_wedge_b}, we simply find that
\begin{equation}\label{equ_a_wedge_b_is_neg_a_dot_b_and_ab}
a\wedge b = -a\cdot b + ab,
\end{equation}
showing that it too may be written as a sum of blades or that of spades.  Indeed, one aim of this paper
is to show that the sum-of-spades form of every element is as natural and perhaps as important as its sum-of-blades form.
Existence of the sum-of-spades form for every element is easily proven, as we'll see by equation \eqref{} later on.  Nothing
of uniquess of either form up to scale and term-ordering is addressed in this paper, but may be worth investigation.

\subsection{The Inner Product And Sums Of Blades}

Letting $a$ denote a vector and $B_r$ a blade of grade $r$ having the factorization
given in equation \eqref{equ_B_r}, we wish here to express the inner product $a\cdot B_r$ as a sum of blades.
Since the case $r=1$ is trivial, we begin by writing, for all $r>1$,
\begin{align}
a\cdot B_r
 &= a\cdot(B_{r-1}\wedge b_r)\nonumber \\
 &= (-1)^{r-1}a\cdot(b_r\wedge B_{r-1})\label{a_dot_Br_stepA} \\
 &= -(-1)^r\left(-b_r\wedge(a\cdot B_{r-1})+(a\cdot b_r)B_{r-1}\right)\label{a_dot_Br_stepB} \\
 &= -(-1)^r\left(-(-1)^r(a\cdot B_{r-1})\wedge b_r+(a\cdot b_r)B_{r-1}\right)\nonumber \\
 &= (a\cdot B_{r-1})\wedge b_r - (-1)^r(a\cdot b_r)B_{r-1}.\label{equ_a_dot_Br_recursive}
\end{align}
Here, we've gone from equation \eqref{a_dot_Br_stepA} to that of \eqref{a_dot_Br_stepB} by
applying the identity given in equation \eqref{equ_a_dot_b_wedge_Br_identity}.

Applied recursively, it is easy to see here from equation \eqref{equ_a_dot_Br_recursive} that an expansion of
$a\cdot B_r$ as a sum of blades is given by
\begin{equation}\label{equ_a_dot_Br_sum_of_blades}
a\cdot B_r = \langle B_r\rangle_0a - \sum_{i=1}^r(-1)^i(a\cdot b_i)\bigwedge_{\substack{j=1\\j\neq i}}^r b_j.
\end{equation}
One might also simply use equation \eqref{equ_a_dot_Br_recursive} to give an inductive
argument of equation \eqref{equ_a_dot_Br_sum_of_blades}.

Notice that for all $r>0$, the term $\langle B_r\rangle_0a$ vanishes in equation \eqref{equ_a_dot_Br_sum_of_blades},
yet its presence allows us the case $r=0$ if we define the summation to be zero in the vacuous case.

Having established equation \eqref{equ_a_dot_Br_sum_of_blades}, we must now show that $a\cdot B_r$ is,
although it is certainly not immediately obvious, a blade of grade $r-1$.  To that end, we write, for all $r>1$,
\begin{equation*}
a\cdot B_r = (a\cdot B_{r-1})\wedge\left(b_r - \frac{a\cdot b_r}{a\cdot b_{r-1}}b_{r-1}\right),
\end{equation*}
with the understanding that if $a\cdot b_{r-1}$ is zero, we can anti-commute vector factors in equation \eqref{equ_a_dot_Br_sum_of_blades}
until this is the case, or else $a\cdot B_r$ is zero anyway.
An inductive argument can now be easily made that $a\cdot B_r$ is indeed a blade of grade $r-1$.
Notice that this proof works in any geometric algebra, regardless of the associated bilinear form.  In a euclidean geometric
algebra, an easier proof is had by writing
\begin{equation*}
a\cdot B_r = (a_{\perp} + a_{\parallel})\cdot B_r = a_{\parallel}\cdot B_r,
\end{equation*}
where $a_{\perp}$ is the orthogonal rejection $a$ from $B_r$, while $a_{\parallel}$ is the
orthogonal projection of $a$ down onto $B_r$.  The blade $B_r$ can now be orthogonalized,
with $a_{\parallel}$ as a principle factor, using the Gram-Schmidt orthogonalization process.\footnote{This process
cannot always be performed on blades taken from a non-euclidean geometric algebra.  To see this, consider rewriting
$a\wedge b$ as $a\wedge(b+\lambda a)$ where $a\cdot(b+\lambda a)=0$.  In a non-euclidean geometric algebra,
no such scalar $\lambda$ may exist.  For a description of the Gram-Schmidt process, see \cite{}.}
This factor then falls out quite easily, and we're left with a blade of grade $r-1$.

Recall now that for any pair of blades $B_r,C_s$, of grades $r$ and $s$, respectively, that
\begin{equation*}
B_r\cdot C_s = \langle B_rC_s\rangle_{|r-s|}.
\end{equation*}
It is not hard to show that the part of smallest possible grade that can appear in the expansion of $B_rC_s$ is $|r-s|$.
Suppose $r<s$ and consider rewriting $B_r$ as a sum of spades.  Then, the
spade of highest possible rank appearing in the sum is no greater than $r$, showing that by equation \eqref{equ_a_dot_Br_sum_of_blades}
the grade $s$ can be diminished by at most $r$.  Similarly, if $s<r$, the grade $r$ can be diminished by at most $s$.

So to calculate $B_r\cdot C_s$, we could rewrite each of $B_r$ and $C_s$ as sums of spades, distribute, and
then rewrite the resulting sum of spades as a sum of blades; but this, as in many other similar cases, would be highly innefficient in the face of
an identity that could take us to the desired result without the need to convert to and from a sum-of-spades form.
Hoping for a better way, we, for all $1<r\leq s$, write
\begin{align}
B_r\cdot C_s &= \langle B_rC_s\rangle_{s-r}\nonumber \\
 &= \langle (B_{r-1}\wedge b_r)C_s\rangle_{s-r} + \langle (B_{r-1}\cdot b_r)C_s\rangle_{s-r}\nonumber \\
 &= \langle B_{r-1}b_rC_s\rangle_{s-r}\nonumber \\
 &= \langle B_{r-1}(b_r\cdot C_s)\rangle_{s-r} + \langle B_{r-1}(b_r\wedge C_s)\rangle_{s-r}\nonumber \\
 &= B_{r-1}\cdot(b_r\cdot C_s).\label{equ_B_r_dot_C_s_r_less_s}
\end{align}
To see this, we begin by noting that since $r\leq s$, we know that
\begin{equation*}
\langle(B_{r-1}\cdot b_r)C_s\rangle_{s-r}=0
\end{equation*}
as its only possible non-zero part of smallest grade would have grade
\begin{equation*}
|(r-2)-s|=s-r+2.
\end{equation*}
Similarly, we know that
\begin{equation*}
\langle B_{r-1}(b_r\wedge C_s)\rangle_{s-r}=0
\end{equation*}
as its only possible non-zero part of smallest grade would have grade
\begin{equation*}
|(r-1)-(s+1)| = s-r+2.
\end{equation*}
Lastly, we know that
\begin{equation*}
\langle B_{r-1}(b_r\cdot C_s)\rangle_{s-r} = B_{r-1}\cdot(b_r\cdot C_s),
\end{equation*}
by reason that
\begin{equation*}
|(r-1)-(s-1)|=s-r.
\end{equation*}
Similar reasoning as what led us to equation \eqref{equ_B_r_dot_C_s_r_less_s} also leads us to equation \eqref{equ_B_r_dot_C_s_s_less_r}.
For all $1<s\leq r$, we have
\begin{equation}\label{equ_B_r_dot_C_s_s_less_r}
B_r\cdot C_s = (B_r\cdot c_1)\cdot\bigwedge_{i=2}^s c_i.
\end{equation}

Together, equations \eqref{equ_B_r_dot_C_s_r_less_s} and \eqref{equ_B_r_dot_C_s_s_less_r}, in conjunction with equation
\eqref{equ_a_dot_Br_sum_of_blades}, allow us to wittle the inner product of any two blades down
to a sum of blades.  It follows that we have now covered everything we would need to know to take any sum of blades in the inner
product with any other such sum and produce yet another sum of blades.  Now we move on with a consideration
of the inner product and sums of spades.

\subsection{The Inner Product And Sums Of Spades}

Letting $a$ denote a vector and $M_r$ a spade of rank $r$ having the factorization
given in equation \eqref{equ_M_r},
we wish here to express the inner product $a\cdot M_r$ as a sum of spades.
Since the case $r=1$ is trivial, we begin by writing, for all $r>1$,
\begin{align}
a\cdot M_r &= a\cdot (M_{r-1}m_r)\nonumber \\
 &= a\cdot((\langle M_{r-1}\rangle_0 + \langle M_{r-1}\rangle_1 + \langle M_{r-1}\rangle_2^r)m_r)\nonumber \\
 &= \langle M_{r-1}\rangle_0a\cdot m_r + (\langle M_{r-1}\rangle_1\cdot m_r)a\nonumber \\
 &+ (a\cdot\langle M_{r-1}\rangle_1)m_r - (a\cdot m_r)\langle M_{r-1}\rangle_1 + a\cdot(\langle M_{r-1}\rangle_2^rm_r).\label{equ_a_dot_Mr_stepA}
\end{align}
We will return to this equation momentarily.  Until then, to ease notation, let us write $M=\langle M_{r-1}\rangle_2^r$ and see that
\begin{align}
a\cdot(Mm_r)
 &= a\cdot(M\cdot m_r + M\wedge m_r)\nonumber \\
 &= -(-1)^{r-1}a\cdot(m_r\cdot M) + (-1)^{r-1}a\cdot(m_r\wedge M)\label{equ_a_dot_Mr_stepB} \\
 &= (-1)^rm_r\cdot(a\cdot M) - (-1)^r\left[-m_r\wedge(a\cdot M)+(a\cdot m_r)M\right]\label{equ_a_dot_Mr_stepC} \\
 &= (a\cdot M)\cdot m_r + (a\cdot M)\wedge m_r - (-1)^r(a\cdot m_r)M\nonumber \\
 &= (a\cdot M)m_r - (-1)^r(a\cdot m_r)M.\label{equ_a_dot_Mr_stepD}
\end{align}
Note here our use of equations \eqref{equ_a_dot_b_dot_Br_identity} and \eqref{equ_a_dot_b_wedge_Br_identity} to
arrive at equation \eqref{equ_a_dot_Mr_stepC} from \eqref{equ_a_dot_Mr_stepB}.

Returning now to equation \eqref{equ_a_dot_Mr_stepA}, if we plug equation \eqref{equ_a_dot_Mr_stepD} into it
under the assumption that $r$ is odd, we get
\begin{equation}
a\cdot M_r = (a\cdot M_{r-1})m_r + (a\cdot m_r)M_{r-1} - \langle M_{r-1}\rangle_0am_r.
\end{equation}
And if we plug equation \eqref{equ_a_dot_Mr_stepD} into equation \eqref{equ_a_dot_Mr_stepA} under the assumption
that $r$ is even, we get
\begin{equation}
a\cdot M_r = (a\cdot M_{r-1})m_r - (a\cdot m_r)M_{r-1} + (\langle M_{r-1}\rangle_1\cdot m_r)a.
\end{equation}
It then follows, despite the parity of $r$, that
\begin{align}
a\cdot M_r &= (a\cdot M_{r-1})m_r - (-1)^r(a\cdot m_r)M_{r-1}\nonumber \\
 &- \langle M_{r-1}\rangle_0am_r + \langle M_r\rangle_0a.\label{equ_a_dot_Mr_recursive}
\end{align}
Note the use of equation \eqref{equ_gr_zero_part_of_Mr} here in our arrival at equation \eqref{equ_a_dot_Mr_recursive}.

Applied recursively, it is now easy to see from equation \eqref{equ_a_dot_Mr_recursive} that an expansion of
$a\cdot M_r$ as a sum of spades is given by\footnote{Interestingly, equation \eqref{equ_a_dot_Mr_sum_of_spades} shows
that spades, like blades, are natural represenatives of geometric sets.  An explanation of geometric sets is given in \cite{}.}
\begin{equation}\label{equ_a_dot_Mr_sum_of_spades}
a\cdot M_r = \langle M_r\rangle_0a - \sum_{i=1}^r(-1)^i(a\cdot m_i)\prod_{\substack{j=1\\j\neq i}}^rm_j.
\end{equation}
To see this, consider an inductive argument.  The cases $r=0$ and $r=1$ follow trivially by inspection.
Now make the inductive hypothesis that equation \eqref{equ_a_dot_Mr_sum_of_spades} holds for a fixed case $r-1$.
Then, applying the recursive formula \eqref{equ_a_dot_Mr_recursive} to the equation in \eqref{equ_a_dot_Mr_sum_of_spades},
adjusted for the case $a\cdot M_{r-1}$, we get equation \eqref{equ_a_dot_Mr_sum_of_spades}, thereby completing
our proof by induction.

% Can we show that a.M_r is a spade of rank r-1?

It is very interesting now to compare this equation \eqref{equ_a_dot_Mr_sum_of_spades} with that of \eqref{equ_a_dot_Br_sum_of_blades}.
Indeed, the outer and geometric products do appear to have some natural symmetry between them.  But perhaps this really shouldn't have been
too supprising after comparing equations \eqref{equ_ab_is_a_dot_b_and_a_wedge_b} and \eqref{equ_a_wedge_b_is_neg_a_dot_b_and_ab}.

% We're not done here.  We need to address (abc...).M_r = (a.(b.(c. ... M_r)...)).

\subsection{The Expansion Of Blades And Spades}

This section needs to be reworked once the previous section is complete.

To show even more symmetry between the outer and geometric products, here we wish to explore the expansion of
blades as sums of spades, and that of spades as sums of blades.
In the latter case it is shown by equations \eqref{equ_Mr_even} and \eqref{equ_Mr_odd} what grades of blades we may expect in the sum.
In the former case we can expect a similar result in terms of the ranks of spades appearing in the sum by simply
considering the equation
\begin{equation}\label{equ_exp_Br_recursive}
B_r = B_{r-1}b_r - (-1)^rb_r\cdot B_{r-1}.
\end{equation}

But what of an explicit formula for the expansion of $B_r$ as a sum of spades, and that of $M_r$ as a sum of blades?
Surely such formulas exist, and are likely, up to sign, isomorphic to one another in the sense that the outer and geometric products
are interchangable, as is the case between equations \eqref{equ_a_dot_Br_sum_of_blades} and \eqref{equ_a_dot_Mr_sum_of_spades}.
That withstanding, and at the expense of slowing our expansion
algorithm down with the need to do more collection than would otherwise be necessary, here, in this paper, we're going to rely on equation \eqref{} above and
equation \eqref{} below to recursively generate the expansions of blades and spades.
\begin{equation}\label{equ_exp_Mr_recursive}
M_r = \langle M_{r-1}\rangle_1^r\wedge m_r + (-1)^rm_r \cdot M_{r-1}.
\end{equation}
Notice that equation \eqref{equ_exp_Br_recursive} must be used in conjunction with equation \eqref{equ_a_dot_Mr_sum_of_spades}, while
equation \eqref{equ_exp_Mr_recursive} must be used in conjunction with equation \eqref{equ_a_dot_Br_sum_of_blades}.  Realize that, recursively,
$B_{r-1}$ will be a sum of spades, while $M_{r-1}$ will be a sum of blades.

For those disapointed with not finding an explicit formula here for the expansion of blades,
an interesting one is found in \cite[p.~86]{DoranLasenby03}.  A similar result can be derived by a
repeated application of equation \eqref{equ_a_wedge_Br}.

% Give my recursive formula for the expansion of a blade and compare that with the one in the Doran reference.

% There is surely a way to do a similar thing to get an sum of blades expansion of a spade, no?

\section{The Expansion Algorithm}

We have now established enough identities to give an expansion algorithm here capable of expanding
any expression from geometric algebra that we could throw at it.  This is a worth-while cause as many
new-comers to geometric algebra will attest that, all-to-often, in their travels through GA-land, they're
confronted with a sub-expression that stumps them.  It is only until one builds up a sufficient repertoire of
formulas and identities in geometric algebra that these obsticals can become readily defeated.

Before we begin, it should be noted that while the algorithm presented here is certainly not the most efficient
means of expanding any given expression, it will be correct, and at least give some direction on how each
situation might be dealt with.

% Must cite and consider existing methods of implementing GAs on the computer, perhaps using matrices?

Although, with the exception of the inner-product, the operations of geometric algebra are generally associative,
realize that we can impose an arbitrary order on each operation so that any expression becomes a binary tree.
Furthermore, every such tree has the proprety that while the internal nodes are operations, the leaf nodes
are elements of our geometric algebra in either a sum-of-blades or sum-of-spades form.  Our algorithm
will proceed by simply collapsing each internal node to such a leaf, there-by preserving this proprety of the
entire tree at each step.  The algorithm clearly terminates when all but the root node remains, which will clearly be
in one of the two desired forms.  Since converting between these two forms is an operation fundamental to
the algorithm, we can also use it to transform our final result into the desired form.

\begin{algorithmic}
\Function{Expand}{node}
	\If{node is leaf}
		\State\Return node
	\EndIf

	\State leftNode $\gets$ node.leftBranch
	\State rightNode $\gets$ node.rightBranch

	\If{leftNode is not a leaf}
		\State leftNode $\gets$ \Call{Expand}{leftNode}
	\EndIf

	\If{rightNode is not a leaf}
		\State rightNode $\gets$ \Call{Expand}{rightNode}
	\EndIf

	\State resultNode $\gets$ nil

	\If{node.operation is the outer product}
		\State leftNode $\gets$ \Call{Convert}{leftNode,``SumOfBlades''}
		\State rightNode $\gets$ \Call{Convert}{rightNode,``SumOfBlades''}
		\State resultNode $\gets$ \Call{Distribute}{leftNode,rightNode}
	\EndIf
	\If{node.operation is the geometric product}
		\State leftNode $\gets$ \Call{Convert}{leftNode,``SumOfMercers''}
		\State rightNode $\gets$ \Call{Convert}{rightNode,``SumOfMercers''}
		\State resultNode $\gets$ \Call{Distribute}{leftNode,rightNode}
	\EndIf
	\If{node.operation is the inner product}
		\State leftNode $\gets$ \Call{Convert}{leftNode,``SumOfBlades''}
		\State rightNode $\gets$ \Call{Convert}{rightNode,``SumOfBlades''}
		\State resultNode $\gets$ \Call{DistributeAndExpand}{leftNode,rightNode}
	\EndIf
	\If{node.operation is addition}
		\If{rightNode.type is not leftNode.type}
			\State rightNode $\gets$ \Call{Convert}{rightNode,leftNode.type}
		\EndIf
		\State resultNode $\gets$ \Call{Add}{leftNode,rightNode}
	\EndIf
	\State\Return resultNode
\EndFunction
\State rootNode $\gets$ \Call{Expand}{rootNode}
\State rootNode $\gets$ \Call{Convert}{rootNode,``SumOfBlades''}
\end{algorithmic}

Note here that the primary input and output of every function called above is a tree-node housing a data-structure
that is specifically designed to represent a sum of blades or sum of spades.

Go on...

% It might be noted that the reverse can be now be fully justifiably applied to any element of GA.
% Note that the reverse is defined as a linear operator that operates only on geometric products.
% It says nothing of the outer product or inner products.  So we can fully justify it by knowing each ele can be a sum of spades.

% In an actual implementation, i may provide an ability to convert from tree to sum-of-X, and vice-versa.
% At a more granular level, just provide a sum that can contain a mix of spades and blades, (it need not be
% homogeneous of spades or that of blades), then deal with
% each distributed product involving just a pair of sub-products, either of which being a blade or spade.

\section{Appendix Of Identities}\label{sec_identities_appendix}

Identities used in this paper are thrown into this appendix so as not to encumber the main body of the paper.

\subsection{Identities Involving Blades}

Letting $a$ denote a vector, and $B_r$ a blade of grade $r$ having factorization
\begin{equation}\label{equ_B_r}
B_r = \bigwedge_{i=1}^r b_i,
\end{equation}
recall that
\begin{equation}\label{equ_aBr_is_a_dot_Br_and_a_wedge_Br}
aB_r = a\cdot B_r + a\wedge B_r.
\end{equation}
Recalling also the commutativities of $a$ with $B_r$ in the inner and outer products as
\begin{align}
a\cdot B_r &= -(-1)^r B_r\cdot a,\label{equ_a_dot_Br_commutativity} \\
a\wedge B_r &= (-1)^r B_r\wedge a,\label{equ_a_wedge_Br_commutativity}
\end{align}
we find that
\begin{align}
a\cdot B_r &= \frac{1}{2}a\cdot B_r - \frac{1}{2}(-1)^r B_r\cdot a\nonumber \\
 &= \frac{1}{2}(aB_r - a\wedge B_r - (-1)^r(B_ra - B_r\wedge a))\nonumber \\
 &= \frac{1}{2}(aB_r-(-1)^rB_ra),\label{equ_a_dot_Br}
\end{align}
and that
\begin{align}
a\wedge B_r &= \frac{1}{2}a\wedge B_r + \frac{1}{2}(-1)^r B_r\wedge a\nonumber \\
 &= \frac{1}{2}(aB_r - a\cdot B_r + (-1)^r(B_ra - B_r\cdot a))\nonumber \\
 &= \frac{1}{2}(aB_r+(-1)^rB_ra).\label{equ_a_wedge_Br}
\end{align}
Now letting $a$ and $b$ each denote a vector, it is not hard to show that for all $r\geq 1$, we have
\begin{equation}\label{equ_a_dot_b_wedge_Br_identity}
a\cdot(b\wedge B_r) + b\wedge(a\cdot B_r) = (a\cdot b)B_r.
\end{equation}
To that end, we apply equations \eqref{equ_a_dot_Br} and \eqref{equ_a_wedge_Br} in writing
\begin{align*}
a\cdot(b\wedge B_r)
 &= \frac{1}{2}\left(a\frac{1}{2}\left(bB_r + (-1)^rB_rb\right)-(-1)^{r+1}\frac{1}{2}\left(bB_r+(-1)^rB_rb\right)a\right) \\
 &= \frac{1}{4}\left(baB_r + (-1)^raB_rb + (-1)^rbB_ra + B_rba\right), \\
b\wedge(a\cdot B_r)
 &= \frac{1}{2}\left(b\frac{1}{2}\left(aB_r-(-1)^rB_ra\right)+(-1)^{r-1}\frac{1}{2}\left(aB_r-(-1)^rB_ra\right)b\right) \\
 &= \frac{1}{4}\left(baB_r - (-1)^rbB_ra - (-1)^raB_rb + B_rab\right),
\end{align*}
from which it is easy to see that
\begin{align*}
a\cdot(b\wedge B_r)+b\wedge(a\cdot B_r) &= \frac{1}{4}(ab+ba)B_r + \frac{1}{4}B_r(ba+ab) \\
 &= \frac{1}{2}(a\cdot b)B_r + \frac{1}{2}B_r(b\cdot a) = (a\cdot b)B_r.
\end{align*}
Similarly, we must note that for all $r>1$, we have
\begin{equation}\label{equ_a_dot_b_dot_Br_identity}
a\cdot(b\cdot B_r) = -b\cdot(a\cdot B_r).
\end{equation}
To see this, we apply equation \eqref{equ_a_dot_Br} in writing
\begin{align*}
a\cdot(b\cdot B_r)
 &= \frac{1}{2}\left(a\frac{1}{2}\left(bB_r-(-1)^rB_rb\right)-(-1)^{r-1}\frac{1}{2}\left(bB_r-(-1)^rB_rb\right)a\right) \\
 &= \frac{1}{4}\left(abB_r - (-1)^raB_rb + (-1)^rbB_ra - B_rba\right),
\end{align*}
Then, by substitution, we can immediately write
\begin{equation*}
b\cdot(a\cdot B_r) = \frac{1}{4}\left(baB_r - (-1)^rbB_ra + (-1)^raB_rb - B_rab\right).
\end{equation*}
Adding these, we then see that
\begin{align*}
a\cdot (b\cdot B)+b\cdot(a\cdot B)
 &= \frac{1}{4}\left(abB_r+baB_r\right)-\frac{1}{4}\left(B_rba+B_rab\right) \\
 &= \frac{1}{4}\left(ab+ba\right)B_r-\frac{1}{4}B_r\left(ba+ab\right) \\
 &= \frac{1}{2}(a\cdot b)B_r - \frac{1}{2}B_r(b\cdot a) = 0.
\end{align*}
Note that we may have arrived at this conclusion sooner had we written
\begin{equation*}
a\cdot(b\cdot B_r) = (a\wedge b)\cdot B_r = -(b\wedge a)\cdot B_r = -b\cdot(a\cdot B_r),
\end{equation*}
but the justification for some intermediate steps is not immediately clear.

\subsection{Identities Involving Spades}

Letting $M_r$ denote a spade of rank $r$ having factorization
\begin{equation}\label{equ_M_r}
M_r = \prod_{i=1}^r m_i,
\end{equation}
recall that
\begin{equation*}
M_r = \sum_{i=1}^r\left\langle M_r\right\rangle_i,
\end{equation*}
where here we're making use of the angled-brackets notation $\langle\cdot\rangle_i$ which takes the grade $i$ part of
what it encloses.  (Note that this requires us to visualize the expansion of the enclosure as a sum of blades.)  To be more precise,
if $M_r$ is a spade of even rank, (if $r$ is even), then
\begin{equation}\label{equ_Mr_even}
M_r = \sum_{i=0}^{r/2}\left\langle M_r\right\rangle_{2i},
\end{equation}
while if $M_r$ is a spade of odd rank, we have
\begin{equation}\label{equ_Mr_odd}
M_r = \sum_{i=1}^{(r+1)/2}\left\langle M_r\right\rangle_{2i-1}.
\end{equation}
To see this, consider first the trivial case of $r=0$; then, for any $r>0$, the equation
\begin{equation}\label{equ_Mr_split}
M_r = M_{r-1}m_r = \langle M_{r-1}\rangle_1^r\cdot m_r + \langle M_{r-1}\rangle_1^r\wedge m_r + \langle M_{r-1}\rangle_0 m_r.
\end{equation}
Here we have extended our notation $\langle\cdot\rangle_i^j$ to mean a culling of all enclosed blades not of a grade falling
in the interval $[i,j]$.

An inductive hypothesis can now be stated that equations \eqref{equ_Mr_even} and \eqref{equ_Mr_odd} hold for $r-1$.
If $r$ is even, then, by our inductive hypothesis, $M_{r-1}$, when expanded as a sum of blades, consists only of blades of odd grade,
and it is clear that equation \eqref{equ_Mr_split} becomes \eqref{equ_Mr_even}.  If $r$ is odd, then, by our inductive hypothesis, $M_{r-1}$, when expanded as
a sum of blades, consists only of blades of even grade, and it is clear that equation \eqref{equ_Mr_split} becomes \eqref{equ_Mr_odd}.

Now let $a$ be a vector, and convince yourself that
\begin{align}
a\cdot M_r &= -(-1)^r M_r\cdot a,\label{equ_a_dot_Mr_commutativity} \\
a\wedge M_r &= (-1)^r M_r\wedge a.\label{equ_a_wedge_Mr_commutativity}
\end{align}
Refer to equations \eqref{equ_a_dot_Br_commutativity} and \eqref{equ_a_wedge_Br_commutativity} to see this.

We now turn our attention to the following identity.
\begin{equation}\label{equ_gr_zero_part_of_Mr}
\langle M_r\rangle_0 = \langle M_{r-1}\rangle_1\cdot m_r
\end{equation}
Note that this is trivial in the case that $r$ is odd, since neither $M_r$ nor $M_{r-1}$ have parts of grade zero nor one, respectively.
Letting $r$ be even, we write
\begin{equation*}
M_r = M_{r-1}m_r = M_{r-1}\cdot m_r + M_{r-1}\wedge m_r - \langle M_r\rangle_0 m_r.
\end{equation*}
Now taking the grade zero part of both sides, we get
\begin{equation*}
\langle M_r\rangle_0 = \langle M_{r-1}\cdot m_r\rangle_0 = \langle M_{r-1}\rangle_1\cdot m_r.
\end{equation*}

\begin{thebibliography}{9}

\bibitem{DoranLasenby03}
C. Doran, A. Lasenby, {\it Geometric Algebra for Physicists}. Cambridge University Press, 2003.

% Ref new foundations for classical mechanics
% Ref GA for CS
% Ref Algorithms book
% Ref my own work where applicable?

\end{thebibliography}

\end{document}